{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b344f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# ChArUco 보드 설정 (전역 변수로 설정)\n",
    "CHARUCO_SQUARES_X = 13\n",
    "CHARUCO_SQUARES_Y = 9\n",
    "CHARUCO_SQUARE_LENGTH = 0.04  # 미터 단위\n",
    "CHARUCO_MARK_LENGTH = 0.02  # 미터 단위\n",
    "\n",
    "corner_threshold = 20  # SIFT feature와 ChArUco corner 간 거리 임계값 (픽셀 단위)\n",
    "\n",
    "def create_charuco_board():\n",
    "    \"\"\"ChArUco 보드 객체 생성\"\"\"\n",
    "    aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_5X5_100)\n",
    "    board = cv2.aruco.CharucoBoard(\n",
    "        (CHARUCO_SQUARES_X, CHARUCO_SQUARES_Y),\n",
    "        CHARUCO_SQUARE_LENGTH,\n",
    "        CHARUCO_MARK_LENGTH,\n",
    "        aruco_dict\n",
    "    )\n",
    "    return board, aruco_dict\n",
    "\n",
    "# 전역 보드 객체\n",
    "BOARD, ARUCO_DICT = create_charuco_board()\n",
    "\n",
    "def detect_charuco_corners_in_image(img):\n",
    "    \"\"\"\n",
    "    이미지에서 ChArUco corner 검출 (world coordinates 매핑용)\n",
    "    \n",
    "    Returns:\n",
    "    - corners: 검출된 corner 2D 좌표\n",
    "    - ids: corner ID \n",
    "    - world_coords: 대응하는 3D world coordinates\n",
    "    \"\"\"\n",
    "    detector = cv2.aruco.ArucoDetector(ARUCO_DICT)\n",
    "    \n",
    "    # ArUco 마커 검출\n",
    "    marker_corners, marker_ids, _ = detector.detectMarkers(img)\n",
    "    \n",
    "    if len(marker_corners) == 0:\n",
    "        return None, None, None\n",
    "    \n",
    "    # ChArUco corner 보간\n",
    "    ret, charuco_corners, charuco_ids = cv2.aruco.interpolateCornersCharuco(\n",
    "        marker_corners, marker_ids, img, BOARD\n",
    "    )\n",
    "    \n",
    "    if ret == 0 or charuco_corners is None:\n",
    "        return None, None, None\n",
    "    \n",
    "    # Corner ID로부터 world coordinates 생성\n",
    "    world_coords = []\n",
    "    for corner_id in charuco_ids.flatten():\n",
    "        corners_per_row = CHARUCO_SQUARES_X - 1\n",
    "        row = corner_id // corners_per_row\n",
    "        col = corner_id % corners_per_row\n",
    "        \n",
    "        world_x = (col + 1) * CHARUCO_SQUARE_LENGTH\n",
    "        world_y = (row + 1) * CHARUCO_SQUARE_LENGTH\n",
    "        world_coords.append([world_x, world_y, 0.0])\n",
    "    \n",
    "    return charuco_corners.reshape(-1, 2), charuco_ids.flatten(), np.array(world_coords)\n",
    "\n",
    "def sift_match_for_visualize(img1, img2, ratio_thresh=0.75, corner_threshold=corner_threshold):\n",
    "    \"\"\"\n",
    "    더 관대한 버전 - corner 근처 조건을 완화\n",
    "    \"\"\"\n",
    "    # 순수 SIFT 매칭\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "    \n",
    "    if len(kp1) == 0 or len(kp2) == 0:\n",
    "        return [], None, None\n",
    "    \n",
    "    bf = cv2.BFMatcher()\n",
    "    raw_matches = bf.knnMatch(des1, des2, k=2)\n",
    "    \n",
    "    sift_matches = []\n",
    "    for match_pair in raw_matches:\n",
    "        if len(match_pair) == 2:\n",
    "            m, n = match_pair\n",
    "            if m.distance < ratio_thresh * n.distance:\n",
    "                pt1 = kp1[m.queryIdx].pt\n",
    "                pt2 = kp2[m.trainIdx].pt\n",
    "                sift_matches.append((pt1, pt2))\n",
    "    \n",
    "    print(f\"SIFT matches (relaxed): {len(sift_matches)}\")\n",
    "    \n",
    "    # ChArUco corner 검출\n",
    "    corners1, ids1, world_coords1 = detect_charuco_corners_in_image(img1)\n",
    "    corners2, ids2, world_coords2 = detect_charuco_corners_in_image(img2)\n",
    "    \n",
    "    if corners1 is None or corners2 is None:\n",
    "        return sift_matches, None, None\n",
    "    \n",
    "    # 더 관대한 매칭 - corner ID 일치 조건 완화\n",
    "    good_matches = []\n",
    "    matched_world_coords = []\n",
    "    \n",
    "    for pt1, pt2 in sift_matches:\n",
    "        # img1에서 가장 가까운 corner\n",
    "        distances1 = np.linalg.norm(corners1 - np.array(pt1), axis=1)\n",
    "        min_idx1 = np.argmin(distances1)\n",
    "        \n",
    "        # img2에서 가장 가까운 corner  \n",
    "        distances2 = np.linalg.norm(corners2 - np.array(pt2), axis=1)\n",
    "        min_idx2 = np.argmin(distances2)\n",
    "        \n",
    "        # 임계값 내에 있으면 매칭 (corner ID 일치 조건 제거)\n",
    "        if distances1[min_idx1] < corner_threshold and distances2[min_idx2] < corner_threshold:\n",
    "            good_matches.append((pt1, pt2))\n",
    "            matched_world_coords.append(world_coords1[min_idx1])\n",
    "    \n",
    "    print(f\"Relaxed matches with world coordinates: {len(good_matches)}\")\n",
    "    \n",
    "    return good_matches, np.array(matched_world_coords) if matched_world_coords else None, None\n",
    "\n",
    "def sift_match(img1, corner_threshold=corner_threshold):\n",
    "    \"\"\"\n",
    "    단일 이미지에서 SIFT feature와 ChArUco corner 연결\n",
    "    \n",
    "    Parameters:\n",
    "    - img1: 입력 이미지\n",
    "    - corner_threshold: SIFT feature와 ChArUco corner 간 거리 임계값 (픽셀)\n",
    "    \n",
    "    Returns:\n",
    "    - good_matches: [(sift_pt, charuco_corner), ...] SIFT-ChArUco 연결 쌍\n",
    "    - matched_world_coords: 대응하는 3D world coordinates\n",
    "    - sift_features: 모든 SIFT feature 점들 (참고용)\n",
    "    \"\"\"\n",
    "    # SIFT feature 검출\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    \n",
    "    if len(kp1) == 0:\n",
    "        print(\"SIFT feature 검출 실패\")\n",
    "        return [], None, []\n",
    "    \n",
    "    # SIFT feature 좌표 추출\n",
    "    sift_points = np.array([kp.pt for kp in kp1])\n",
    "    # print(f\"SIFT features detected: {len(sift_points)}\")\n",
    "    \n",
    "    # ChArUco corner 검출\n",
    "    corners1, ids1, world_coords1 = detect_charuco_corners_in_image(img1)\n",
    "    \n",
    "    if corners1 is None:\n",
    "        print(\"ChArUco corner 검출 실패\")\n",
    "        return [], None, sift_points.tolist()\n",
    "    \n",
    "    # print(f\"ChArUco corners detected: {len(corners1)}\")\n",
    "    \n",
    "    # SIFT feature와 가장 가까운 ChArUco corner 연결\n",
    "    good_matches = []\n",
    "    matched_world_coords = []\n",
    "    \n",
    "    for sift_pt in sift_points:\n",
    "        # 가장 가까운 ChArUco corner 찾기\n",
    "        distances = np.linalg.norm(corners1 - sift_pt, axis=1)\n",
    "        min_idx = np.argmin(distances)\n",
    "        min_distance = distances[min_idx]\n",
    "        \n",
    "        # 임계값 내에 있으면 연결\n",
    "        if min_distance < corner_threshold:\n",
    "            charuco_corner = corners1[min_idx]\n",
    "            corner_id = ids1[min_idx]\n",
    "            world_coord = world_coords1[min_idx]\n",
    "            \n",
    "            good_matches.append((tuple(sift_pt), tuple(charuco_corner)))\n",
    "            matched_world_coords.append(world_coord)\n",
    "            \n",
    "            # print(f\"SIFT-ChArUco match: Corner ID {corner_id}, distance {min_distance:.1f}px\")\n",
    "    \n",
    "    # print(f\"Total SIFT-ChArUco matches: {len(good_matches)}\")\n",
    "    \n",
    "    return (good_matches, \n",
    "            np.array(matched_world_coords) if matched_world_coords else None, \n",
    "            sift_points.tolist())\n",
    "\n",
    "def draw_sift_matches(img1, img2, matches):\n",
    "    \"\"\"\n",
    "    매칭 결과 시각화 (기존 함수 유지)\n",
    "    \"\"\"\n",
    "    h1, w1 = img1.shape\n",
    "    h2, w2 = img2.shape\n",
    "    canvas = np.zeros((max(h1, h2), w1 + w2), dtype=np.uint8)\n",
    "    canvas[:h1, :w1] = img1\n",
    "    canvas[:h2, w1:] = img2\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.imshow(canvas, cmap='gray')\n",
    "\n",
    "    if len(matches) > 0:\n",
    "        cmap = plt.cm.get_cmap('hsv', len(matches))\n",
    "        for i, ((x1, y1), (x2, y2)) in enumerate(matches):\n",
    "            color = cmap(i)\n",
    "            plt.plot([x1, x2 + w1], [y1, y2], color=color, linewidth=2, marker='o', markersize=6)\n",
    "    \n",
    "    plt.title(f\"SIFT Matches with ChArUco World Coords: {len(matches)} matches\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "IMAGE_DIR = Path('camera_images3')\n",
    "\n",
    "img1 = cv2.imread(str(IMAGE_DIR / '0.jpeg'), cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread(str(IMAGE_DIR / '1.jpeg'), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "matches, kp1, kp2 = sift_match_for_visualize(img1, img2)\n",
    "# print(f\"# of good matches: {len(matches)}\")\n",
    "\n",
    "draw_sift_matches(img1, img2, matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ec5a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_homography(matches):\n",
    "    A = []\n",
    "    for (x, y), (xp, yp) in matches:\n",
    "        A.append([-x, -y, -1, 0, 0, 0, x*xp, y*xp, xp])\n",
    "        A.append([0, 0, 0, -x, -y, -1, x*yp, y*yp, yp])\n",
    "    A = np.array(A)\n",
    "\n",
    "    # SVD\n",
    "    U, S, Vt = np.linalg.svd(A)\n",
    "    h = Vt[-1, :]\n",
    "    H = h.reshape(3, 3)\n",
    "    return H / H[2, 2]\n",
    "\n",
    "def average_reprojection_error(matches, H):\n",
    "    total_error = 0\n",
    "    for (x, y), (xp, yp) in matches:\n",
    "        p = np.array([x, y, 1.0])\n",
    "        projected = H @ p\n",
    "        projected /= projected[2]\n",
    "        error = np.linalg.norm(projected[:2] - np.array([xp, yp]))\n",
    "        total_error += error\n",
    "    return total_error / len(matches)\n",
    "\n",
    "H = compute_homography(matches)\n",
    "error = average_reprojection_error(matches, H)\n",
    "print(f\"Average Reprojection Error: {error:.4f} pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75cf748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def ransac_homography(matches, threshold=3.0, iterations=1000):\n",
    "    best_H = None\n",
    "    max_inliers = 0\n",
    "    best_inliers = []\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        sample = random.sample(matches, 4)\n",
    "        H_candidate = compute_homography(sample)\n",
    "        inliers = []\n",
    "        if matches is None or len(matches) < 4:\n",
    "            print(\"Not enough matches for RANSAC\")\n",
    "            continue\n",
    "        else:\n",
    "            for (x, y), (xp, yp) in matches:\n",
    "                p = np.array([x, y, 1.0])\n",
    "                projected = H_candidate @ p\n",
    "                projected /= projected[2]\n",
    "                error = np.linalg.norm(projected[:2] - np.array([xp, yp]))\n",
    "                if error < threshold:\n",
    "                    inliers.append(((x, y), (xp, yp)))\n",
    "\n",
    "            if len(inliers) > max_inliers:\n",
    "                max_inliers = len(inliers)\n",
    "                best_H = H_candidate\n",
    "                best_inliers = inliers\n",
    "\n",
    "    return best_H, best_inliers\n",
    "\n",
    "H_ransac, inlier_matches = ransac_homography(matches, threshold=5.0, iterations=1000)\n",
    "error = average_reprojection_error(inlier_matches, H_ransac)\n",
    "\n",
    "print(f\"RANSAC Homography Inliers: {len(inlier_matches)} / {len(matches)}\")\n",
    "print(f\"Average Reprojection Error after RANSAC: {error:.4f} pixels\")\n",
    "\n",
    "draw_sift_matches(img1, img2, inlier_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f174469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 이미지에 대해 Homography 계산\n",
    "import os\n",
    "\n",
    "filenames = sorted(os.listdir(IMAGE_DIR), key=lambda x: int(x.split('.')[0]))\n",
    "H_list = []\n",
    "\n",
    "# 기준 카메라: 0th image\n",
    "img0_path = str(IMAGE_DIR / filenames[0])\n",
    "img0 = cv2.imread(img0_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "for i in range(0, len(filenames)):\n",
    "    img_path = str(IMAGE_DIR / filenames[i])\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    matches, kp1, kp2 = sift_match(img)\n",
    "    print(f\"Matching image{i}: {len(matches)} good matches\")\n",
    "    if len(matches) < 4:\n",
    "        print(f\"Not enough matches for image0 and image{i}, skipping...\")\n",
    "        continue\n",
    "    H_ransac, inlier_matches = ransac_homography(matches, threshold=5.0, iterations=1000)\n",
    "    error = average_reprojection_error(inlier_matches, H_ransac)\n",
    "\n",
    "    H_list.append(H_ransac)\n",
    "\n",
    "    print(f\"RANSAC Homography for image{i}:\")\n",
    "    print(f\"Inliers: {len(inlier_matches)} / {len(matches)}\")\n",
    "    # print(f\"Homography Matrix:\\n{H_ransac}\\n\")\n",
    "    # print(f\"Homography determinant: {np.linalg.det(H_ransac):.4f}\")\n",
    "    print(f\"Average Reprojection Error: {error:.4f} pixels\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da983b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_v_ij(H, i, j):\n",
    "    return np.array([\n",
    "        H[0, i]*H[0, j],\n",
    "        H[0, i]*H[1, j] + H[1, i]*H[0, j],\n",
    "        H[1, i]*H[1, j],\n",
    "        H[2, i]*H[0, j] + H[0, i]*H[2, j],\n",
    "        H[2, i]*H[1, j] + H[1, i]*H[2, j],\n",
    "        H[2, i]*H[2, j]\n",
    "    ])\n",
    "\n",
    "def estimate_intrinsics(H_list):\n",
    "    V = []\n",
    "    for H in H_list:\n",
    "        v12 = compute_v_ij(H, 0, 1)\n",
    "        v11 = compute_v_ij(H, 0, 0)\n",
    "        v22 = compute_v_ij(H, 1, 1)\n",
    "        V.append(v12)\n",
    "        V.append(v11 - v22)\n",
    "    V = np.array(V)\n",
    "\n",
    "    # Solve Vb = 0 using SVD\n",
    "    _, _, Vt = np.linalg.svd(V)\n",
    "    b = Vt[-1, :]\n",
    "\n",
    "    # Extract parameters from b\n",
    "    B11, B12, B22, B13, B23, B33 = b\n",
    "    v0 = (B12*B13 - B11*B23) / (B11*B22 - B12**2)\n",
    "    lam = B33 - (B13**2 + v0*(B12*B13 - B11*B23)) / B11\n",
    "    # print(f'lam: {lam}, B11: {B11}, (B11*B22 - B12**2): {B11*B22 - B12**2}, lab* B11: {lam / B11}')\n",
    "    alpha = np.sqrt(lam / B11)\n",
    "    beta = np.sqrt(lam * B11 / (B11*B22 - B12**2))\n",
    "    gamma = -B12 * alpha**2 * beta / lam\n",
    "    u0 = gamma * v0 / beta - B13 * alpha**2 / lam\n",
    "\n",
    "    # Construct K matrix\n",
    "    K = np.array([\n",
    "        [alpha, gamma, u0],\n",
    "        [0,     beta,  v0],\n",
    "        [0,     0,     1]\n",
    "    ])\n",
    "    return K\n",
    "\n",
    "def estimate_extrinsics(H, K):\n",
    "    K_inv = np.linalg.inv(K)\n",
    "    h1 = H[:, 0]\n",
    "    h2 = H[:, 1]\n",
    "    h3 = H[:, 2]\n",
    "\n",
    "    lambda_ = 1.0 / np.linalg.norm(K_inv @ h1)\n",
    "    r1 = lambda_ * (K_inv @ h1)\n",
    "    r2 = lambda_ * (K_inv @ h2)\n",
    "    r3 = np.cross(r1, r2)\n",
    "    t = lambda_ * (K_inv @ h3)\n",
    "\n",
    "    # Ensure R is a valid rotation matrix using orthonormalization (SVD)\n",
    "    R = np.stack([r1, r2, r3], axis=1)\n",
    "    U, _, Vt = np.linalg.svd(R)\n",
    "    R_orthonormal = U @ Vt\n",
    "\n",
    "    return R_orthonormal, t\n",
    "\n",
    "def is_valid_homography(H, cond_thresh=1e6):\n",
    "    return (\n",
    "        np.isfinite(H).all() and \n",
    "        np.abs(H[2, 2] - 1.0) < 1e-3 and \n",
    "        np.linalg.cond(H) < cond_thresh\n",
    "    )\n",
    "\n",
    "def estimate_extrinsics_safe(H_list, K, cond_thresh=1e8):\n",
    "    extrinsics = []\n",
    "    for i, H in enumerate(H_list):\n",
    "        if not is_valid_homography(H, cond_thresh):\n",
    "            print(f\"⚠️ Skipping H[{i}] due to high condition number: {np.linalg.cond(H):.2e}\")\n",
    "            continue\n",
    "        try:\n",
    "            R, t = estimate_extrinsics(H, K)\n",
    "            if R is not None:\n",
    "                extrinsics.append((R, t))\n",
    "        except np.linalg.LinAlgError:\n",
    "            print(f\"⚠️ SVD failed for H[{i}]\")\n",
    "    return extrinsics\n",
    "\n",
    "K = estimate_intrinsics(H_list)\n",
    "print(\"Estimated Intrinsic Matrix K:\\n\", K)\n",
    "\n",
    "# First camera's extrinsics (identity for the first camera)\n",
    "extrinsics = [(np.eye(3), np.zeros(3))]\n",
    "\n",
    "# Append the extrinsics for the other cameras\n",
    "for idx, H in enumerate(H_list):\n",
    "    # if idx == 0:\n",
    "    #     continue  # Skip the first camera\n",
    "    R, t = estimate_extrinsics(H, K)\n",
    "    print(f\"Image {idx+1}:\")\n",
    "    print(\"Rotation Matrix R:\\n\", R)\n",
    "    print(\"Translation Vector t:\\n\", t)\n",
    "    print()\n",
    "    extrinsics.append((R, t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88513312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot_camera_frustum(ax, R, camera_center, scale):\n",
    "    \"\"\"\n",
    "    카메라 프러스텀(시야각)을 시각화하는 함수\n",
    "    \"\"\"\n",
    "    # 프러스텀 크기\n",
    "    frustum_length = scale * 1.5\n",
    "    frustum_width = scale * 0.8\n",
    "    frustum_height = scale * 0.6\n",
    "    \n",
    "    # 프러스텀 모서리 점들 (카메라 좌표계에서)\n",
    "    frustum_points_local = np.array([\n",
    "        [0, 0, 0],  # 카메라 중심\n",
    "        [-frustum_width, -frustum_height, frustum_length],  # 좌하\n",
    "        [frustum_width, -frustum_height, frustum_length],   # 우하\n",
    "        [frustum_width, frustum_height, frustum_length],    # 우상\n",
    "        [-frustum_width, frustum_height, frustum_length]    # 좌상\n",
    "    ])\n",
    "    \n",
    "    # 월드 좌표계로 변환\n",
    "    frustum_points_world = []\n",
    "    for point in frustum_points_local:\n",
    "        world_point = R @ point + camera_center\n",
    "        frustum_points_world.append(world_point)\n",
    "    \n",
    "    frustum_points_world = np.array(frustum_points_world)\n",
    "    \n",
    "    # 프러스텀 선 그리기\n",
    "    # 카메라 중심에서 각 모서리로\n",
    "    for i in range(1, 5):\n",
    "        ax.plot([frustum_points_world[0, 0], frustum_points_world[i, 0]],\n",
    "                [frustum_points_world[0, 1], frustum_points_world[i, 1]],\n",
    "                [frustum_points_world[0, 2], frustum_points_world[i, 2]], \n",
    "                'gray', alpha=0.4, linewidth=1)\n",
    "    \n",
    "    # 프러스텀 사각형 그리기\n",
    "    for i in range(1, 5):\n",
    "        next_i = i + 1 if i < 4 else 1\n",
    "        ax.plot([frustum_points_world[i, 0], frustum_points_world[next_i, 0]],\n",
    "                [frustum_points_world[i, 1], frustum_points_world[next_i, 1]],\n",
    "                [frustum_points_world[i, 2], frustum_points_world[next_i, 2]], \n",
    "                'gray', alpha=0.4, linewidth=1)\n",
    "\n",
    "# Visualize camera extrinsics in 3D space\n",
    "def plot_camera_poses(K, extrinsics):\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # World coordinate axes\n",
    "    ax.quiver(0, 0, 0, 1, 0, 0, color='r', length=0.5)\n",
    "    ax.quiver(0, 0, 0, 0, 1, 0, color='g', length=0.5)\n",
    "    ax.quiver(0, 0, 0, 0, 0, 1, color='b', length=0.5)\n",
    "\n",
    "    for idx, (R, t) in enumerate(extrinsics):\n",
    "        # Camera center in world coordinates\n",
    "        C = -R.T @ t\n",
    "\n",
    "        # Draw camera axis\n",
    "        cam_axis = R.T\n",
    "        ax.quiver(C[0], C[1], C[2], cam_axis[0, 0], cam_axis[1, 0], cam_axis[2, 0], color='r', length=0.3)\n",
    "        ax.quiver(C[0], C[1], C[2], cam_axis[0, 1], cam_axis[1, 1], cam_axis[2, 1], color='g', length=0.3)\n",
    "        ax.quiver(C[0], C[1], C[2], cam_axis[0, 2], cam_axis[1, 2], cam_axis[2, 2], color='b', length=0.3)\n",
    "\n",
    "        ax.text(C[0], C[1], C[2], f\"Cam{idx+1}\", color='black')\n",
    "\n",
    "        plot_camera_frustum(ax, R, C, scale=500)\n",
    "\n",
    "    ax.set_title(\"Estimated Camera Poses\")\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_zlabel(\"Z\")\n",
    "    ax.view_init(elev=30, azim=-60)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_camera_poses(K, extrinsics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3D_CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
