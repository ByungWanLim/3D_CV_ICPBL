{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c985b1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import math\n",
    "\n",
    "def load_images(folder_path):\n",
    "    \"\"\"\n",
    "    지정된 폴더에서 이미지들을 로드하는 함수\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): 이미지가 있는 폴더 경로\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (로드된 이미지들의 리스트, 이미지 경로들)\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    image_paths = []\n",
    "    \n",
    "    # 지원하는 이미지 확장자\n",
    "    extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']\n",
    "    \n",
    "    for ext in extensions:\n",
    "        pattern = os.path.join(folder_path, ext)\n",
    "        image_paths.extend(glob.glob(pattern))\n",
    "    \n",
    "    image_paths.sort()  # 정렬하여 일관된 순서 보장\n",
    "    \n",
    "    for path in image_paths:\n",
    "        img = cv2.imread(path)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            print(f\"로드된 이미지: {os.path.basename(path)}\")\n",
    "    \n",
    "    print(f\"총 {len(images)}개의 이미지가 로드되었습니다.\")\n",
    "    return images, image_paths\n",
    "\n",
    "def try_multiple_aruco_dicts():\n",
    "    \"\"\"\n",
    "    다양한 ArUco 딕셔너리를 반환하는 함수\n",
    "    \n",
    "    Returns:\n",
    "        list: ArUco 딕셔너리들의 리스트\n",
    "    \"\"\"\n",
    "    dict_types = [\n",
    "        cv2.aruco.DICT_5X5_50,\n",
    "    ]\n",
    "    \n",
    "    dict_names = [\n",
    "        \"DICT_5X5_50\",\n",
    "    ]\n",
    "    \n",
    "    return dict_types, dict_names\n",
    "\n",
    "def create_charuco_board(squares_x=14, squares_y=10, square_length=0.04, marker_length=0.02, dict_type=cv2.aruco.DICT_6X6_250):\n",
    "    \"\"\"\n",
    "    ChArUco 보드를 생성하는 함수\n",
    "    \n",
    "    Args:\n",
    "        squares_x (int): 가로 방향 사각형 개수\n",
    "        squares_y (int): 세로 방향 사각형 개수\n",
    "        square_length (float): 사각형 크기 (미터)\n",
    "        marker_length (float): ArUco 마커 크기 (미터)\n",
    "        dict_type: ArUco 딕셔너리 타입\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (ChArUco 보드 객체, ArUco 딕셔너리)\n",
    "    \"\"\"\n",
    "    aruco_dict = cv2.aruco.getPredefinedDictionary(dict_type)\n",
    "    \n",
    "    board = cv2.aruco.CharucoBoard(\n",
    "        (squares_x, squares_y),\n",
    "        square_length,\n",
    "        marker_length,\n",
    "        aruco_dict\n",
    "    )\n",
    "    \n",
    "    return board, aruco_dict\n",
    "\n",
    "def detect_aruco_with_multiple_params(gray_img, aruco_dict):\n",
    "    \"\"\"\n",
    "    다양한 파라미터로 ArUco 마커 검출을 시도하는 함수\n",
    "    \n",
    "    Args:\n",
    "        gray_img: 그레이스케일 이미지\n",
    "        aruco_dict: ArUco 딕셔너리\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (마커 코너들, 마커 ID들, 검출된 파라미터 정보)\n",
    "    \"\"\"\n",
    "    # 기본 파라미터\n",
    "    parameters = cv2.aruco.DetectorParameters()\n",
    "    \n",
    "    # 파라미터 조정 옵션들\n",
    "    param_sets = [\n",
    "        # 기본 설정\n",
    "        {},\n",
    "        # 더 관대한 설정 1\n",
    "        {\n",
    "            'adaptiveThreshWinSizeMin': 3,\n",
    "            'adaptiveThreshWinSizeMax': 23,\n",
    "            'adaptiveThreshWinSizeStep': 10,\n",
    "            'adaptiveThreshConstant': 7\n",
    "        },\n",
    "        # 더 관대한 설정 2\n",
    "        {\n",
    "            'adaptiveThreshWinSizeMin': 3,\n",
    "            'adaptiveThreshWinSizeMax': 50,\n",
    "            'adaptiveThreshWinSizeStep': 4,\n",
    "            'adaptiveThreshConstant': 7,\n",
    "            'minMarkerPerimeterRate': 0.03,\n",
    "            'maxMarkerPerimeterRate': 4.0\n",
    "        },\n",
    "        # 매우 관대한 설정\n",
    "        {\n",
    "            'adaptiveThreshWinSizeMin': 3,\n",
    "            'adaptiveThreshWinSizeMax': 100,\n",
    "            'adaptiveThreshConstant': 5,\n",
    "            'minMarkerPerimeterRate': 0.01,\n",
    "            'maxMarkerPerimeterRate': 10.0,\n",
    "            'polygonalApproxAccuracyRate': 0.1,\n",
    "            'minCornerDistanceRate': 0.01,\n",
    "            'minDistanceToBorder': 1\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for i, param_set in enumerate(param_sets):\n",
    "        # 파라미터 설정\n",
    "        params = cv2.aruco.DetectorParameters()\n",
    "        for key, value in param_set.items():\n",
    "            setattr(params, key, value)\n",
    "        \n",
    "        detector = cv2.aruco.ArucoDetector(aruco_dict, params)\n",
    "        marker_corners, marker_ids, _ = detector.detectMarkers(gray_img)\n",
    "        \n",
    "        if len(marker_corners) > 0:\n",
    "            print(f\"파라미터 세트 {i+1}에서 {len(marker_corners)}개 마커 검출\")\n",
    "            return marker_corners, marker_ids, f\"파라미터 세트 {i+1}\"\n",
    "    \n",
    "    return [], None, \"검출 실패\"\n",
    "\n",
    "def detect_charuco_with_fallback(images):\n",
    "    \"\"\"\n",
    "    다양한 방법으로 ChArUco 또는 체커보드 검출을 시도하는 함수\n",
    "    \n",
    "    Args:\n",
    "        images: 입력 이미지들\n",
    "    \n",
    "    Returns:\n",
    "        tuple: 검출 결과들\n",
    "    \"\"\"\n",
    "    dict_types, dict_names = try_multiple_aruco_dicts()\n",
    "    \n",
    "    # 다양한 보드 크기 시도\n",
    "    board_sizes = [\n",
    "        (13, 9),\n",
    "        # (14, 10), (10, 14), (13, 9), (9, 13), \n",
    "        # (12, 8), (8, 12), (11, 7), (7, 11),\n",
    "        # (10, 6), (6, 10), (9, 6), (6, 9)\n",
    "    ]\n",
    "    \n",
    "    print(\"다양한 ArUco 딕셔너리와 보드 크기로 검출 시도 중...\")\n",
    "    \n",
    "    for dict_idx, (dict_type, dict_name) in enumerate(zip(dict_types, dict_names)):\n",
    "        print(f\"\\n{dict_name} 딕셔너리 시도 중...\")\n",
    "        \n",
    "        for board_size in board_sizes:\n",
    "            try:\n",
    "                board, aruco_dict = create_charuco_board(\n",
    "                    squares_x=board_size[0], \n",
    "                    squares_y=board_size[1],\n",
    "                    dict_type=dict_type\n",
    "                )\n",
    "                \n",
    "                all_corners = []\n",
    "                all_ids = []\n",
    "                valid_images = []\n",
    "                detection_info = []\n",
    "                \n",
    "                success_count = 0\n",
    "                \n",
    "                for i, img in enumerate(images):\n",
    "                    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                    \n",
    "                    # 다양한 파라미터로 ArUco 마커 검출\n",
    "                    marker_corners, marker_ids, param_info = detect_aruco_with_multiple_params(gray, aruco_dict)\n",
    "                    \n",
    "                    if len(marker_corners) > 0:\n",
    "                        # ChArUco 코너 검출\n",
    "                        ret, charuco_corners, charuco_ids = cv2.aruco.interpolateCornersCharuco(\n",
    "                            marker_corners, marker_ids, gray, board\n",
    "                        )\n",
    "                        \n",
    "                        if ret > 0:\n",
    "                            success_count += 1\n",
    "                            print(f\"  이미지 {i+1}: {len(marker_corners)}개 ArUco 마커, {ret}개 ChArUco 코너 검출 ({param_info})\")\n",
    "                            all_corners.append(charuco_corners)\n",
    "                            all_ids.append(charuco_ids)\n",
    "                            valid_images.append(img.copy())\n",
    "                            \n",
    "                            detection_info.append({\n",
    "                                'image_idx': i,\n",
    "                                'marker_corners': marker_corners,\n",
    "                                'marker_ids': marker_ids,\n",
    "                                'charuco_corners': charuco_corners,\n",
    "                                'charuco_ids': charuco_ids,\n",
    "                                'num_markers': len(marker_corners),\n",
    "                                'num_corners': ret,\n",
    "                                'board_size': board_size,\n",
    "                                'dict_name': dict_name\n",
    "                            })\n",
    "                \n",
    "                if success_count >= 2:\n",
    "                    print(f\"\\n성공! {dict_name}, 보드 크기 {board_size}에서 {success_count}개 이미지 검출\")\n",
    "                    return all_corners, all_ids, valid_images, detection_info, board, aruco_dict\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  보드 크기 {board_size} 오류: {e}\")\n",
    "                continue\n",
    "    \n",
    "    print(\"\\nChArUco 검출 실패. 일반 체커보드 검출로 전환합니다...\")\n",
    "    return detect_regular_checkerboard(images)\n",
    "\n",
    "def detect_regular_checkerboard(images):\n",
    "    \"\"\"\n",
    "    일반 체커보드 검출을 수행하는 함수 (백업 방법)\n",
    "    \n",
    "    Args:\n",
    "        images: 입력 이미지들\n",
    "    \n",
    "    Returns:\n",
    "        tuple: 검출 결과들\n",
    "    \"\"\"\n",
    "    # 다양한 체커보드 크기 시도\n",
    "    checkerboard_sizes = [\n",
    "        (13, 9),\n",
    "    ]\n",
    "    \n",
    "    for size in checkerboard_sizes:\n",
    "        print(f\"체커보드 크기 {size} 시도 중...\")\n",
    "        \n",
    "        objp = np.zeros((size[0] * size[1], 3), np.float32)\n",
    "        objp[:, :2] = np.mgrid[0:size[0], 0:size[1]].T.reshape(-1, 2)\n",
    "        \n",
    "        objpoints = []\n",
    "        imgpoints = []\n",
    "        valid_images = []\n",
    "        detection_info = []\n",
    "        \n",
    "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "        success_count = 0\n",
    "        \n",
    "        for i, img in enumerate(images):\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            ret, corners = cv2.findChessboardCorners(gray, size, None)\n",
    "            \n",
    "            if ret:\n",
    "                success_count += 1\n",
    "                print(f\"  이미지 {i+1}에서 체커보드 검출 성공\")\n",
    "                objpoints.append(objp)\n",
    "                \n",
    "                corners_refined = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "                imgpoints.append(corners_refined)\n",
    "                valid_images.append(img.copy())\n",
    "                \n",
    "                detection_info.append({\n",
    "                    'image_idx': i,\n",
    "                    'corners': corners_refined,\n",
    "                    'board_size': size,\n",
    "                    'type': 'regular_checkerboard'\n",
    "                })\n",
    "        \n",
    "        if success_count >= 2:\n",
    "            print(f\"일반 체커보드 검출 성공! 크기 {size}에서 {success_count}개 이미지 검출\")\n",
    "            return objpoints, imgpoints, valid_images, detection_info, None, None\n",
    "    \n",
    "    print(\"모든 검출 방법이 실패했습니다.\")\n",
    "    return None, None, None, None, None, None\n",
    "\n",
    "def selective_visualization_control():\n",
    "    \"\"\"\n",
    "    시각화 제어를 위한 설정 함수\n",
    "    \n",
    "    Returns:\n",
    "        dict: 시각화 옵션들\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'show_detection_results': True,     # 검출 결과 표시 여부\n",
    "        'show_reprojection_errors': True,   # 재투영 오차 표시 여부\n",
    "        'show_feature_matching': True,      # 특징점 매칭 표시 여부\n",
    "        'show_3d_camera_view': True,        # 3D 카메라 뷰 표시 여부\n",
    "        'max_images_per_plot': 6,           # 한 번에 표시할 최대 이미지 수\n",
    "        'max_matches_display': 50,          # 표시할 최대 매칭 수\n",
    "        'save_plots': False,                # 플롯을 파일로 저장할지 여부\n",
    "        'show_first_n_images': None,        # 처음 N개 이미지만 표시 (None이면 모두)\n",
    "        'max_matching_pairs': 5,            # 최대 매칭 쌍 수\n",
    "    }\n",
    "\n",
    "def visualize_detection_results_batch(valid_images, detection_info, max_images_per_plot=6, save_plots=False):\n",
    "    \"\"\"\n",
    "    검출 결과를 배치로 시각화하는 개선된 함수\n",
    "    \n",
    "    Args:\n",
    "        valid_images: 유효한 이미지들\n",
    "        detection_info: 검출 정보들\n",
    "        max_images_per_plot: 한 번에 표시할 최대 이미지 수\n",
    "        save_plots: 플롯을 파일로 저장할지 여부\n",
    "    \"\"\"\n",
    "    total_images = len(valid_images)\n",
    "    \n",
    "    if total_images == 0:\n",
    "        print(\"시각화할 이미지가 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    # 이미지를 배치로 나누기\n",
    "    num_batches = math.ceil(total_images / max_images_per_plot)\n",
    "    \n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * max_images_per_plot\n",
    "        end_idx = min(start_idx + max_images_per_plot, total_images)\n",
    "        batch_size = end_idx - start_idx\n",
    "        \n",
    "        # 동적으로 subplot 구성 계산\n",
    "        if batch_size <= 2:\n",
    "            rows, cols = 1, batch_size\n",
    "        elif batch_size <= 4:\n",
    "            rows, cols = 2, 2\n",
    "        elif batch_size <= 6:\n",
    "            rows, cols = 2, 3\n",
    "        else:\n",
    "            rows, cols = 3, 3\n",
    "        \n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(15, 10))\n",
    "        if batch_size == 1:\n",
    "            axes = [axes]\n",
    "        elif rows == 1 or cols == 1:\n",
    "            axes = axes.flatten()\n",
    "        else:\n",
    "            axes = axes.flatten()\n",
    "        \n",
    "        fig.suptitle(f'Detection Results - Batch {batch_idx + 1}/{num_batches}', fontsize=16)\n",
    "        \n",
    "        for i, (img, info) in enumerate(zip(valid_images[start_idx:end_idx], \n",
    "                                          detection_info[start_idx:end_idx])):\n",
    "            img_copy = img.copy()\n",
    "            \n",
    "            if info.get('type') == 'regular_checkerboard':\n",
    "                # 일반 체커보드\n",
    "                cv2.drawChessboardCorners(img_copy, info['board_size'], \n",
    "                                        info['corners'], True)\n",
    "                info_text = f\"Checkerboard: {info['board_size']}\"\n",
    "            else:\n",
    "                # ChArUco\n",
    "                if info.get('marker_corners') is not None:\n",
    "                    cv2.aruco.drawDetectedMarkers(img_copy, info['marker_corners'], \n",
    "                                                info['marker_ids'])\n",
    "                \n",
    "                if info.get('charuco_corners') is not None:\n",
    "                    cv2.aruco.drawDetectedCornersCharuco(img_copy, info['charuco_corners'], \n",
    "                                                      info['charuco_ids'])\n",
    "                \n",
    "                info_text = f\"ArUco: {info['num_markers']}, ChArUco: {info['num_corners']}\"\n",
    "            \n",
    "            # 이미지 표시\n",
    "            axes[i].imshow(cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB))\n",
    "            axes[i].set_title(f\"Image {start_idx + i + 1}\\n{info_text}\", fontsize=10)\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        # 사용하지 않는 subplot 숨기기\n",
    "        for j in range(batch_size, len(axes)):\n",
    "            axes[j].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_plots:\n",
    "            plt.savefig(f'detection_results_batch_{batch_idx + 1}.png', dpi=150, bbox_inches='tight')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "def visualize_reprojection_errors_improved(valid_images, poses, corners_or_objpoints, ids_or_imgpoints,\n",
    "                                         camera_matrix, dist_coeffs, detection_info, board=None, \n",
    "                                         detection_type='charuco', max_images_per_plot=6):\n",
    "    \"\"\"\n",
    "    개선된 재투영 오차 시각화 함수\n",
    "    \n",
    "    Args:\n",
    "        valid_images: 유효한 이미지들\n",
    "        poses: 추정된 포즈들\n",
    "        corners_or_objpoints: 코너 또는 객체점들\n",
    "        ids_or_imgpoints: ID 또는 이미지점들  \n",
    "        camera_matrix: 카메라 행렬\n",
    "        dist_coeffs: 왜곡 계수\n",
    "        detection_info: 검출 정보\n",
    "        board: ChArUco 보드\n",
    "        detection_type: 검출 타입\n",
    "        max_images_per_plot: 한 번에 표시할 최대 이미지 수\n",
    "    \"\"\"\n",
    "    # 성공한 포즈들만 필터링\n",
    "    successful_data = []\n",
    "    for i, (success, R, t, error) in enumerate(poses):\n",
    "        if success:\n",
    "            successful_data.append((i, R, t, error, valid_images[i], detection_info[i]))\n",
    "    \n",
    "    if not successful_data:\n",
    "        print(\"시각화할 성공한 포즈가 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    total_successful = len(successful_data)\n",
    "    num_batches = math.ceil(total_successful / max_images_per_plot)\n",
    "    \n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * max_images_per_plot\n",
    "        end_idx = min(start_idx + max_images_per_plot, total_successful)\n",
    "        batch_size = end_idx - start_idx\n",
    "        \n",
    "        # 동적으로 subplot 구성 계산\n",
    "        if batch_size <= 2:\n",
    "            rows, cols = 1, batch_size\n",
    "        elif batch_size <= 4:\n",
    "            rows, cols = 2, 2\n",
    "        elif batch_size <= 6:\n",
    "            rows, cols = 2, 3\n",
    "        else:\n",
    "            rows, cols = 3, 3\n",
    "        \n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(15, 10))\n",
    "        if batch_size == 1:\n",
    "            axes = [axes]\n",
    "        elif rows == 1 or cols == 1:\n",
    "            axes = axes.flatten()\n",
    "        else:\n",
    "            axes = axes.flatten()\n",
    "        \n",
    "        fig.suptitle(f'Reprojection Error Visualization - Batch {batch_idx + 1}/{num_batches}\\n'\n",
    "                    f'(Green: detected points, Red: reprojected points)', fontsize=14)\n",
    "        \n",
    "        for plot_idx, data_idx in enumerate(range(start_idx, end_idx)):\n",
    "            i, R, t, error, img, info = successful_data[data_idx]\n",
    "            \n",
    "            img_copy = img.copy()\n",
    "            \n",
    "            if detection_type == 'charuco':\n",
    "                # ChArUco 재투영\n",
    "                if info['charuco_corners'] is not None:\n",
    "                    obj_points = board.getChessboardCorners()[info['charuco_ids'].flatten()]\n",
    "                    \n",
    "                    rvec, _ = cv2.Rodrigues(R)\n",
    "                    projected_points, _ = cv2.projectPoints(\n",
    "                        obj_points, rvec, t, camera_matrix, dist_coeffs\n",
    "                    )\n",
    "                    \n",
    "                    # 원본 점들 (초록색)\n",
    "                    for point in info['charuco_corners']:\n",
    "                        cv2.circle(img_copy, tuple(point[0].astype(int)), 5, (0, 255, 0), -1)\n",
    "                    \n",
    "                    # 재투영된 점들 (빨간색)\n",
    "                    for point in projected_points:\n",
    "                        cv2.circle(img_copy, tuple(point[0].astype(int)), 3, (0, 0, 255), -1)\n",
    "                    \n",
    "                    # 오차 선 그리기\n",
    "                    for orig, proj in zip(info['charuco_corners'], projected_points):\n",
    "                        cv2.line(img_copy, tuple(orig[0].astype(int)), tuple(proj[0].astype(int)), \n",
    "                                (255, 0, 0), 1)\n",
    "            else:\n",
    "                # 일반 체커보드 재투영\n",
    "                board_size = info['board_size']\n",
    "                objp = np.zeros((board_size[0] * board_size[1], 3), np.float32)\n",
    "                objp[:, :2] = np.mgrid[0:board_size[0], 0:board_size[1]].T.reshape(-1, 2)\n",
    "                \n",
    "                rvec, _ = cv2.Rodrigues(R)\n",
    "                projected_points, _ = cv2.projectPoints(\n",
    "                    objp, rvec, t, camera_matrix, dist_coeffs\n",
    "                )\n",
    "                \n",
    "                # 원본 점들 (초록색)\n",
    "                for point in info['corners']:\n",
    "                    cv2.circle(img_copy, tuple(point[0].astype(int)), 3, (0, 255, 0), -1)\n",
    "                \n",
    "                # 재투영된 점들 (빨간색)  \n",
    "                for point in projected_points:\n",
    "                    cv2.circle(img_copy, tuple(point[0].astype(int)), 2, (0, 0, 255), -1)\n",
    "            \n",
    "            axes[plot_idx].imshow(cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB))\n",
    "            axes[plot_idx].set_title(f'Image {i+1}\\nReprojection Error: {error:.4f} pixels', fontsize=10)\n",
    "            axes[plot_idx].axis('off')\n",
    "        \n",
    "        # 사용하지 않는 subplot 숨기기\n",
    "        for j in range(batch_size, len(axes)):\n",
    "            axes[j].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def visualize_matches_universal_improved(img1, img2, points1, points2, title=\"Feature Matching\", \n",
    "                                       max_matches_display=50):\n",
    "    \"\"\"\n",
    "    개선된 범용 매칭 시각화 함수\n",
    "    \n",
    "    Args:\n",
    "        img1, img2: 입력 이미지들\n",
    "        points1, points2: 매칭된 특징점들\n",
    "        title: 플롯 제목\n",
    "        max_matches_display: 표시할 최대 매칭 수 (너무 많으면 시각화가 복잡해짐)\n",
    "    \"\"\"\n",
    "    # 너무 많은 매칭점이 있으면 샘플링\n",
    "    if len(points1) > max_matches_display:\n",
    "        indices = np.random.choice(len(points1), max_matches_display, replace=False)\n",
    "        points1_display = points1[indices]\n",
    "        points2_display = points2[indices]\n",
    "        display_info = f\" (showing {max_matches_display}/{len(points1)} matches)\"\n",
    "    else:\n",
    "        points1_display = points1\n",
    "        points2_display = points2\n",
    "        display_info = \"\"\n",
    "    \n",
    "    kp1 = [cv2.KeyPoint(x, y, 1) for x, y in points1_display]\n",
    "    kp2 = [cv2.KeyPoint(x, y, 1) for x, y in points2_display]\n",
    "    matches = [cv2.DMatch(i, i, 0) for i in range(len(points1_display))]\n",
    "    \n",
    "    img_matches = cv2.drawMatches(img1, kp1, img2, kp2, matches, None,\n",
    "                                 flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.imshow(cv2.cvtColor(img_matches, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"{title}\\nMatched Feature Points: {len(points1)}{display_info}\", fontsize=16)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def match_features_universal(data1, data2, detection_type):\n",
    "    \"\"\"\n",
    "    범용 특징점 매칭 함수\n",
    "    \"\"\"\n",
    "    if detection_type == 'charuco':\n",
    "        # ChArUco 매칭\n",
    "        corners1, ids1 = data1\n",
    "        corners2, ids2 = data2\n",
    "        \n",
    "        ids1_flat = ids1.flatten()\n",
    "        ids2_flat = ids2.flatten()\n",
    "        common_ids = np.intersect1d(ids1_flat, ids2_flat)\n",
    "        \n",
    "        if len(common_ids) == 0:\n",
    "            return None, None, None\n",
    "        \n",
    "        matched_corners1 = []\n",
    "        matched_corners2 = []\n",
    "        \n",
    "        for common_id in common_ids:\n",
    "            idx1 = np.where(ids1_flat == common_id)[0]\n",
    "            idx2 = np.where(ids2_flat == common_id)[0]\n",
    "            \n",
    "            if len(idx1) > 0 and len(idx2) > 0:\n",
    "                matched_corners1.append(corners1[idx1[0]])\n",
    "                matched_corners2.append(corners2[idx2[0]])\n",
    "        \n",
    "        if len(matched_corners1) >= 4:\n",
    "            matched_corners1 = np.array(matched_corners1).reshape(-1, 2)\n",
    "            matched_corners2 = np.array(matched_corners2).reshape(-1, 2)\n",
    "            return matched_corners1, matched_corners2, common_ids\n",
    "        \n",
    "    else:\n",
    "        # 일반 체커보드 매칭\n",
    "        corners1 = data1.reshape(-1, 2)\n",
    "        corners2 = data2.reshape(-1, 2)\n",
    "        return corners1, corners2, None\n",
    "    \n",
    "    return None, None, None\n",
    "\n",
    "def compute_homography_ransac(points1, points2, ransac_threshold=5.0):\n",
    "    \"\"\"\n",
    "    RANSAC을 사용하여 robust한 호모그래피를 계산하는 함수\n",
    "    \"\"\"\n",
    "    if len(points1) >= 4:\n",
    "        H, mask = cv2.findHomography(points1, points2, \n",
    "                                   cv2.RANSAC, \n",
    "                                   ransac_threshold)\n",
    "        return H, mask\n",
    "    else:\n",
    "        print(\"호모그래피 계산을 위해서는 최소 4개의 점이 필요합니다.\")\n",
    "        return None, None\n",
    "\n",
    "def calibrate_camera_universal(corners_or_objpoints, ids_or_imgpoints, valid_images, \n",
    "                              detection_info, board=None, detection_type='charuco'):\n",
    "    \"\"\"\n",
    "    범용 카메라 캘리브레이션 함수\n",
    "    \n",
    "    Args:\n",
    "        corners_or_objpoints: ChArUco 코너 또는 객체점들\n",
    "        ids_or_imgpoints: ChArUco ID 또는 이미지점들  \n",
    "        valid_images: 유효한 이미지들\n",
    "        detection_info: 검출 정보\n",
    "        board: ChArUco 보드 (ChArUco 모드에서만)\n",
    "        detection_type: 검출 타입 ('charuco' 또는 'regular_checkerboard')\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (성공여부, 카메라행렬, 왜곡계수, 회전벡터들, 변환벡터들, 재투영오차)\n",
    "    \"\"\"\n",
    "    if len(valid_images) < 3:\n",
    "        print(\"카메라 캘리브레이션을 위해서는 최소 3개의 유효한 이미지가 필요합니다.\")\n",
    "        return False, None, None, None, None, None\n",
    "    \n",
    "    image_size = (valid_images[0].shape[1], valid_images[0].shape[0])\n",
    "    print(f\"이미지 크기: {image_size}\")\n",
    "    print(f\"캘리브레이션에 사용될 이미지 수: {len(valid_images)}\")\n",
    "    \n",
    "    if detection_type == 'charuco':\n",
    "        # ChArUco 캘리브레이션\n",
    "        print(\"ChArUco 패턴을 사용한 카메라 캘리브레이션 수행 중...\")\n",
    "        ret, camera_matrix, dist_coeffs, rvecs, tvecs = cv2.aruco.calibrateCameraCharuco(\n",
    "            corners_or_objpoints, ids_or_imgpoints, board, image_size, None, None\n",
    "        )\n",
    "    else:\n",
    "        # 일반 체커보드 캘리브레이션\n",
    "        print(\"일반 체커보드 패턴을 사용한 카메라 캘리브레이션 수행 중...\")\n",
    "        ret, camera_matrix, dist_coeffs, rvecs, tvecs = cv2.calibrateCamera(\n",
    "            corners_or_objpoints, ids_or_imgpoints, image_size, None, None\n",
    "        )\n",
    "    \n",
    "    return ret, camera_matrix, dist_coeffs, rvecs, tvecs, ret\n",
    "\n",
    "def estimate_pose_for_each_image(corners_or_objpoints, ids_or_imgpoints, camera_matrix, \n",
    "                                dist_coeffs, detection_info, board=None, detection_type='charuco'):\n",
    "    \"\"\"\n",
    "    각 이미지에 대해 개별적으로 외부 파라미터를 추정하는 함수\n",
    "    \n",
    "    Args:\n",
    "        corners_or_objpoints: 코너 또는 객체점들\n",
    "        ids_or_imgpoints: ID 또는 이미지점들\n",
    "        camera_matrix: 카메라 내부 파라미터 행렬\n",
    "        dist_coeffs: 왜곡 계수\n",
    "        detection_info: 검출 정보\n",
    "        board: ChArUco 보드\n",
    "        detection_type: 검출 타입\n",
    "    \n",
    "    Returns:\n",
    "        list: 각 이미지의 포즈 정보 [(성공여부, R, t, 재투영오차), ...]\n",
    "    \"\"\"\n",
    "    poses = []\n",
    "    \n",
    "    for i, info in enumerate(detection_info):\n",
    "        print(f\"\\n이미지 {i+1}의 포즈 추정 중...\")\n",
    "        \n",
    "        if detection_type == 'charuco':\n",
    "            # ChArUco에서 3D-2D 대응점 생성\n",
    "            if info['charuco_corners'] is not None and len(info['charuco_corners']) >= 4:\n",
    "                # 보드에서 3D 좌표 얻기\n",
    "                obj_points = board.getChessboardCorners()[info['charuco_ids'].flatten()]\n",
    "                img_points = info['charuco_corners']\n",
    "                \n",
    "                # PnP 문제 해결\n",
    "                success, rvec, tvec = cv2.solvePnP(\n",
    "                    obj_points, img_points, camera_matrix, dist_coeffs\n",
    "                )\n",
    "                \n",
    "                if success:\n",
    "                    # 회전 벡터를 회전 행렬로 변환\n",
    "                    R, _ = cv2.Rodrigues(rvec)\n",
    "                    \n",
    "                    # 재투영 오차 계산\n",
    "                    projected_points, _ = cv2.projectPoints(\n",
    "                        obj_points, rvec, tvec, camera_matrix, dist_coeffs\n",
    "                    )\n",
    "                    reprojection_error = np.mean(np.linalg.norm(\n",
    "                        img_points.reshape(-1, 2) - projected_points.reshape(-1, 2), axis=1\n",
    "                    ))\n",
    "                    \n",
    "                    poses.append((True, R, tvec, reprojection_error))\n",
    "                    print(f\"  포즈 추정 성공, 재투영 오차: {reprojection_error:.4f} 픽셀\")\n",
    "                else:\n",
    "                    poses.append((False, None, None, None))\n",
    "                    print(\"  포즈 추정 실패\")\n",
    "            else:\n",
    "                poses.append((False, None, None, None))\n",
    "                print(\"  충분한 특징점이 없음\")\n",
    "        \n",
    "        else:\n",
    "            # 일반 체커보드에서 포즈 추정\n",
    "            board_size = info['board_size']\n",
    "            \n",
    "            # 3D 객체점 생성\n",
    "            objp = np.zeros((board_size[0] * board_size[1], 3), np.float32)\n",
    "            objp[:, :2] = np.mgrid[0:board_size[0], 0:board_size[1]].T.reshape(-1, 2)\n",
    "            \n",
    "            img_points = info['corners']\n",
    "            \n",
    "            # PnP 문제 해결\n",
    "            success, rvec, tvec = cv2.solvePnP(\n",
    "                objp, img_points, camera_matrix, dist_coeffs\n",
    "            )\n",
    "            \n",
    "            if success:\n",
    "                # 회전 벡터를 회전 행렬로 변환\n",
    "                R, _ = cv2.Rodrigues(rvec)\n",
    "                \n",
    "                # 재투영 오차 계산\n",
    "                projected_points, _ = cv2.projectPoints(\n",
    "                    objp, rvec, tvec, camera_matrix, dist_coeffs\n",
    "                )\n",
    "                reprojection_error = np.mean(np.linalg.norm(\n",
    "                    img_points.reshape(-1, 2) - projected_points.reshape(-1, 2), axis=1\n",
    "                ))\n",
    "                \n",
    "                poses.append((True, R, tvec, reprojection_error))\n",
    "                print(f\"  포즈 추정 성공, 재투영 오차: {reprojection_error:.4f} 픽셀\")\n",
    "            else:\n",
    "                poses.append((False, None, None, None))\n",
    "                print(\"  포즈 추정 실패\")\n",
    "    \n",
    "    return poses\n",
    "\n",
    "def analyze_camera_parameters(camera_matrix, dist_coeffs, image_size):\n",
    "    \"\"\"\n",
    "    카메라 파라미터를 분석하는 함수\n",
    "    \n",
    "    Args:\n",
    "        camera_matrix: 카메라 내부 파라미터 행렬\n",
    "        dist_coeffs: 왜곡 계수\n",
    "        image_size: 이미지 크기\n",
    "    \n",
    "    Returns:\n",
    "        dict: 분석된 파라미터들\n",
    "    \"\"\"\n",
    "    fx, fy = camera_matrix[0, 0], camera_matrix[1, 1]\n",
    "    cx, cy = camera_matrix[0, 2], camera_matrix[1, 2]\n",
    "    \n",
    "    # 화각 계산 (라디안 -> 도)\n",
    "    fov_x = 2 * np.arctan(image_size[0] / (2 * fx)) * 180 / np.pi\n",
    "    fov_y = 2 * np.arctan(image_size[1] / (2 * fy)) * 180 / np.pi\n",
    "    \n",
    "    # 픽셀 크기 추정 (일반적인 센서 크기 가정)\n",
    "    sensor_width_mm = 36  # 35mm 풀프레임 가정\n",
    "    pixel_size_um = (sensor_width_mm * 1000) / image_size[0]\n",
    "    \n",
    "    analysis = {\n",
    "        'focal_length_x': fx,\n",
    "        'focal_length_y': fy,\n",
    "        'focal_length_avg': (fx + fy) / 2,\n",
    "        'principal_point': (cx, cy),\n",
    "        'image_center': (image_size[0]/2, image_size[1]/2),\n",
    "        'principal_point_offset': (cx - image_size[0]/2, cy - image_size[1]/2),\n",
    "        'field_of_view_x': fov_x,\n",
    "        'field_of_view_y': fov_y,\n",
    "        'aspect_ratio': fx / fy,\n",
    "        'pixel_size_estimate_um': pixel_size_um,\n",
    "        'distortion_coefficients': dist_coeffs.flatten()\n",
    "    }\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "def print_calibration_results(ret, camera_matrix, dist_coeffs, poses, analysis):\n",
    "    \"\"\"\n",
    "    캘리브레이션 결과를 출력하는 함수\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"카메라 캘리브레이션 결과\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if ret:\n",
    "        print(f\"✓ 캘리브레이션 성공!\")\n",
    "        print(f\"✓ 전체 재투영 오차 (RMS): {ret:.4f} 픽셀\")\n",
    "        \n",
    "        print(f\"\\n📷 카메라 내부 파라미터 행렬 (K):\")\n",
    "        print(f\"   [{camera_matrix[0,0]:8.2f}  {camera_matrix[0,1]:8.2f}  {camera_matrix[0,2]:8.2f}]\")\n",
    "        print(f\"   [{camera_matrix[1,0]:8.2f}  {camera_matrix[1,1]:8.2f}  {camera_matrix[1,2]:8.2f}]\")\n",
    "        print(f\"   [{camera_matrix[2,0]:8.2f}  {camera_matrix[2,1]:8.2f}  {camera_matrix[2,2]:8.2f}]\")\n",
    "        \n",
    "        print(f\"\\n🔍 상세 파라미터 분석:\")\n",
    "        print(f\"   • 초점거리 (fx, fy): ({analysis['focal_length_x']:.2f}, {analysis['focal_length_y']:.2f}) 픽셀\")\n",
    "        print(f\"   • 평균 초점거리: {analysis['focal_length_avg']:.2f} 픽셀\")\n",
    "        print(f\"   • 주점 (cx, cy): ({analysis['principal_point'][0]:.2f}, {analysis['principal_point'][1]:.2f})\")\n",
    "        print(f\"   • 이미지 중심에서 오프셋: ({analysis['principal_point_offset'][0]:.2f}, {analysis['principal_point_offset'][1]:.2f})\")\n",
    "        print(f\"   • 화각 (FOV): {analysis['field_of_view_x']:.1f}° × {analysis['field_of_view_y']:.1f}°\")\n",
    "        print(f\"   • 종횡비 (fx/fy): {analysis['aspect_ratio']:.4f}\")\n",
    "        print(f\"   • 추정 픽셀 크기: {analysis['pixel_size_estimate_um']:.2f} μm\")\n",
    "        \n",
    "        print(f\"\\n🌊 왜곡 계수:\")\n",
    "        dist_names = ['k1', 'k2', 'p1', 'p2', 'k3']\n",
    "        for i, (name, coeff) in enumerate(zip(dist_names, dist_coeffs.flatten())):\n",
    "            if i < len(dist_coeffs.flatten()):\n",
    "                print(f\"   • {name}: {coeff:.6f}\")\n",
    "    else:\n",
    "        print(\"❌ 캘리브레이션 실패\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "\n",
    "# 3D 시각화 관련 함수들\n",
    "def plot_camera_views(poses, detection_info, board=None, detection_type='charuco', \n",
    "                     camera_matrix=None, scale_factor=0.1):\n",
    "    \"\"\"\n",
    "    3D 공간에서 카메라 뷰들을 시각화하는 함수\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(15, 12))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # 성공한 포즈들만 추출\n",
    "    successful_poses = []\n",
    "    successful_indices = []\n",
    "    \n",
    "    for i, pose_data in enumerate(poses):\n",
    "        # poses 구조 안전하게 처리\n",
    "        if isinstance(pose_data, (list, tuple)) and len(pose_data) >= 3:\n",
    "            if len(pose_data) >= 4:\n",
    "                success, R, t, error = pose_data\n",
    "            else:\n",
    "                success, R, t = pose_data\n",
    "                error = 0.0  # 기본값\n",
    "            \n",
    "            if success and R is not None and t is not None:\n",
    "                successful_poses.append((R, t, error))\n",
    "                successful_indices.append(i)\n",
    "    \n",
    "    if len(successful_poses) == 0:\n",
    "        print(\"시각화할 수 있는 성공한 포즈가 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n{len(successful_poses)}개의 카메라 포즈를 시각화합니다...\")\n",
    "    \n",
    "    # 체커보드/ChArUco 패턴 시각화\n",
    "    if detection_type == 'charuco' and board is not None:\n",
    "        plot_charuco_board_3d(ax, board, scale_factor)\n",
    "    else:\n",
    "        # 일반 체커보드의 경우 첫 번째 이미지의 보드 크기 사용\n",
    "        if len(detection_info) > 0 and successful_indices:\n",
    "            board_size = detection_info[successful_indices[0]]['board_size']\n",
    "            plot_checkerboard_3d(ax, board_size, scale_factor)\n",
    "    \n",
    "    # 각 카메라 포즈 시각화\n",
    "    camera_positions = []\n",
    "    \n",
    "    for i, (R, t, error) in enumerate(successful_poses):\n",
    "        # 카메라 중심 위치 계산: C = -R^T * t\n",
    "        camera_center = -R.T @ t\n",
    "        camera_positions.append(camera_center.flatten())\n",
    "        \n",
    "        # 카메라 시각화\n",
    "        plot_camera_3d(ax, R, camera_center.flatten(), scale_factor, \n",
    "                      f'Camera {successful_indices[i]+1}', error)\n",
    "    \n",
    "    # 카메라 궤적 그리기 (카메라가 3개 이상인 경우)\n",
    "    if len(camera_positions) >= 3:\n",
    "        camera_positions = np.array(camera_positions)\n",
    "        ax.plot(camera_positions[:, 0], camera_positions[:, 1], camera_positions[:, 2], \n",
    "                'b--', alpha=0.6, linewidth=2, label='Camera Trajectory')\n",
    "    \n",
    "    # 좌표축 설정 및 레이블\n",
    "    ax.set_xlabel('X (m)', fontsize=12)\n",
    "    ax.set_ylabel('Y (m)', fontsize=12)\n",
    "    ax.set_zlabel('Z (m)', fontsize=12)\n",
    "    ax.set_title('3D Camera Views and Checkerboard Layout', fontsize=14, pad=20)\n",
    "    \n",
    "    # 범례 추가\n",
    "    ax.legend(loc='upper right')\n",
    "    \n",
    "    # 축 범위 자동 조정\n",
    "    if len(camera_positions) > 0:\n",
    "        all_points = np.array(camera_positions)\n",
    "        center = np.mean(all_points, axis=0)\n",
    "        max_range = np.max(np.abs(all_points - center)) * 1.2\n",
    "        \n",
    "        ax.set_xlim(center[0] - max_range, center[0] + max_range)\n",
    "        ax.set_ylim(center[1] - max_range, center[1] + max_range)\n",
    "        ax.set_zlim(center[2] - max_range, center[2] + max_range)\n",
    "    \n",
    "    # 격자 표시\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 카메라 정보 요약 출력\n",
    "    print_camera_summary(successful_poses, successful_indices, camera_positions)\n",
    "\n",
    "def plot_camera_3d(ax, R, camera_center, scale, label, error):\n",
    "    \"\"\"\n",
    "    3D 공간에서 개별 카메라를 시각화하는 함수\n",
    "    \"\"\"\n",
    "    # 카메라 좌표계 축 벡터\n",
    "    axes_length = scale\n",
    "    \n",
    "    # 카메라 좌표계 (X=빨강, Y=초록, Z=파랑)\n",
    "    x_axis = R[:, 0] * axes_length + camera_center\n",
    "    y_axis = R[:, 1] * axes_length + camera_center  \n",
    "    z_axis = R[:, 2] * axes_length + camera_center\n",
    "    \n",
    "    # 좌표축 그리기\n",
    "    ax.plot([camera_center[0], x_axis[0]], [camera_center[1], x_axis[1]], \n",
    "            [camera_center[2], x_axis[2]], 'r-', linewidth=3, alpha=0.8)\n",
    "    ax.plot([camera_center[0], y_axis[0]], [camera_center[1], y_axis[1]], \n",
    "            [camera_center[2], y_axis[2]], 'g-', linewidth=3, alpha=0.8)\n",
    "    ax.plot([camera_center[0], z_axis[0]], [camera_center[1], z_axis[1]], \n",
    "            [camera_center[2], z_axis[2]], 'b-', linewidth=3, alpha=0.8)\n",
    "    \n",
    "    # 카메라 중심점 표시\n",
    "    ax.scatter(*camera_center, s=100, c='black', marker='o', alpha=0.8)\n",
    "    \n",
    "    # 카메라 프러스텀 (시야각) 표시\n",
    "    if scale > 0:\n",
    "        plot_camera_frustum(ax, R, camera_center, scale)\n",
    "    \n",
    "    # 레이블 추가\n",
    "    ax.text(camera_center[0], camera_center[1], camera_center[2] + scale*0.5, \n",
    "            f'{label}\\nError: {error:.3f}px', fontsize=9, ha='center')\n",
    "\n",
    "def plot_camera_frustum(ax, R, camera_center, scale):\n",
    "    \"\"\"\n",
    "    카메라 프러스텀(시야각)을 시각화하는 함수\n",
    "    \"\"\"\n",
    "    # 프러스텀 크기\n",
    "    frustum_length = scale * 1.5\n",
    "    frustum_width = scale * 0.8\n",
    "    frustum_height = scale * 0.6\n",
    "    \n",
    "    # 프러스텀 모서리 점들 (카메라 좌표계에서)\n",
    "    frustum_points_local = np.array([\n",
    "        [0, 0, 0],  # 카메라 중심\n",
    "        [-frustum_width, -frustum_height, frustum_length],  # 좌하\n",
    "        [frustum_width, -frustum_height, frustum_length],   # 우하\n",
    "        [frustum_width, frustum_height, frustum_length],    # 우상\n",
    "        [-frustum_width, frustum_height, frustum_length]    # 좌상\n",
    "    ])\n",
    "    \n",
    "    # 월드 좌표계로 변환\n",
    "    frustum_points_world = []\n",
    "    for point in frustum_points_local:\n",
    "        world_point = R @ point + camera_center\n",
    "        frustum_points_world.append(world_point)\n",
    "    \n",
    "    frustum_points_world = np.array(frustum_points_world)\n",
    "    \n",
    "    # 프러스텀 선 그리기\n",
    "    # 카메라 중심에서 각 모서리로\n",
    "    for i in range(1, 5):\n",
    "        ax.plot([frustum_points_world[0, 0], frustum_points_world[i, 0]],\n",
    "                [frustum_points_world[0, 1], frustum_points_world[i, 1]],\n",
    "                [frustum_points_world[0, 2], frustum_points_world[i, 2]], \n",
    "                'gray', alpha=0.4, linewidth=1)\n",
    "    \n",
    "    # 프러스텀 사각형 그리기\n",
    "    for i in range(1, 5):\n",
    "        next_i = i + 1 if i < 4 else 1\n",
    "        ax.plot([frustum_points_world[i, 0], frustum_points_world[next_i, 0]],\n",
    "                [frustum_points_world[i, 1], frustum_points_world[next_i, 1]],\n",
    "                [frustum_points_world[i, 2], frustum_points_world[next_i, 2]], \n",
    "                'gray', alpha=0.4, linewidth=1)\n",
    "\n",
    "def plot_charuco_board_3d(ax, board, scale):\n",
    "    \"\"\"\n",
    "    3D 공간에서 ChArUco 보드를 시각화하는 함수\n",
    "    \"\"\"\n",
    "    # ChArUco 보드의 3D 코너 점들 가져오기\n",
    "    board_corners = board.getChessboardCorners()\n",
    "    \n",
    "    if len(board_corners) > 0:\n",
    "        # 보드 평면 (Z=0)에 점들 표시\n",
    "        x_coords = board_corners[:, 0]\n",
    "        y_coords = board_corners[:, 1]\n",
    "        z_coords = board_corners[:, 2]\n",
    "        \n",
    "        # 코너 점들 표시\n",
    "        ax.scatter(x_coords, y_coords, z_coords, c='red', s=20, alpha=0.7, label='ChArUco Corners')\n",
    "        \n",
    "        # 보드 경계 그리기\n",
    "        board_size = board.getChessboardSize()\n",
    "        square_size = board.getSquareLength()\n",
    "        \n",
    "        # 보드 경계 계산\n",
    "        max_x = (board_size[0] - 1) * square_size\n",
    "        max_y = (board_size[1] - 1) * square_size\n",
    "        \n",
    "        # 경계선 그리기\n",
    "        boundary_x = [0, max_x, max_x, 0, 0]\n",
    "        boundary_y = [0, 0, max_y, max_y, 0]\n",
    "        boundary_z = [0, 0, 0, 0, 0]\n",
    "        \n",
    "        ax.plot(boundary_x, boundary_y, boundary_z, 'k-', linewidth=2, alpha=0.8, label='Board Boundary')\n",
    "\n",
    "def plot_checkerboard_3d(ax, board_size, scale):\n",
    "    \"\"\"\n",
    "    3D 공간에서 일반 체커보드를 시각화하는 함수\n",
    "    \"\"\"\n",
    "    # 체커보드 코너 점들 생성 (Z=0 평면)\n",
    "    square_size = scale  # 정사각형 크기\n",
    "    \n",
    "    x_coords = []\n",
    "    y_coords = []\n",
    "    z_coords = []\n",
    "    \n",
    "    for i in range(board_size[0]):\n",
    "        for j in range(board_size[1]):\n",
    "            x_coords.append(i * square_size)\n",
    "            y_coords.append(j * square_size)\n",
    "            z_coords.append(0)\n",
    "    \n",
    "    # 코너 점들 표시\n",
    "    ax.scatter(x_coords, y_coords, z_coords, c='red', s=20, alpha=0.7, label='Checkerboard Corners')\n",
    "    \n",
    "    # 보드 경계 그리기\n",
    "    max_x = (board_size[0] - 1) * square_size\n",
    "    max_y = (board_size[1] - 1) * square_size\n",
    "    \n",
    "    boundary_x = [0, max_x, max_x, 0, 0]\n",
    "    boundary_y = [0, 0, max_y, max_y, 0]\n",
    "    boundary_z = [0, 0, 0, 0, 0]\n",
    "    \n",
    "    ax.plot(boundary_x, boundary_y, boundary_z, 'k-', linewidth=2, alpha=0.8, label='Board Boundary')\n",
    "\n",
    "def print_camera_summary(successful_poses, successful_indices, camera_positions):\n",
    "    \"\"\"\n",
    "    카메라 정보 요약을 출력하는 함수\n",
    "    \"\"\"\n",
    "    print(f\"\\n📷 카메라 궤적 분석 요약:\")\n",
    "    print(f\"=\" * 50)\n",
    "    \n",
    "    camera_positions = np.array(camera_positions)\n",
    "    \n",
    "    # 전체 통계\n",
    "    if len(camera_positions) > 1:\n",
    "        total_distance = 0\n",
    "        for i in range(1, len(camera_positions)):\n",
    "            total_distance += np.linalg.norm(camera_positions[i] - camera_positions[i-1])\n",
    "        \n",
    "        workspace_size = np.max(camera_positions, axis=0) - np.min(camera_positions, axis=0)\n",
    "        \n",
    "        print(f\"🎯 전체 통계:\")\n",
    "        print(f\"   • 총 이동 거리: {total_distance:.3f} m\")\n",
    "        print(f\"   • 작업 공간 크기: {workspace_size[0]:.3f} × {workspace_size[1]:.3f} × {workspace_size[2]:.3f} m\")\n",
    "        print(f\"   • 평균 높이: {np.mean(camera_positions[:, 2]):.3f} m\")\n",
    "        print(f\"   • 높이 범위: {np.min(camera_positions[:, 2]):.3f} ~ {np.max(camera_positions[:, 2]):.3f} m\")\n",
    "\n",
    "def plot_comprehensive_camera_view(calibration_results):\n",
    "    \"\"\"\n",
    "    포괄적인 카메라 뷰 시각화 함수\n",
    "    \"\"\"\n",
    "    poses = calibration_results['poses']\n",
    "    detection_info = calibration_results['detection_info'] \n",
    "    detection_type = calibration_results['detection_type']\n",
    "    camera_matrix = calibration_results['camera_matrix']\n",
    "    \n",
    "    # board 정보 추출\n",
    "    board = None\n",
    "    if detection_type == 'charuco':\n",
    "        # ChArUco 보드 재생성 (detection_info에서 정보 추출)\n",
    "        if len(detection_info) > 0:\n",
    "            # 첫 번째 성공한 검출 정보 사용\n",
    "            for info in detection_info:\n",
    "                if 'board_size' in info:\n",
    "                    board, _ = create_charuco_board(\n",
    "                        squares_x=info['board_size'][0], \n",
    "                        squares_y=info['board_size'][1]\n",
    "                    )\n",
    "                    break\n",
    "    \n",
    "    print(f\"\\n🎬 3D 카메라 뷰 시각화 시작...\")\n",
    "    \n",
    "    # 1. 메인 3D 뷰\n",
    "    plot_camera_views(poses, detection_info, board, detection_type, camera_matrix)\n",
    "    \n",
    "    return True\n",
    "\n",
    "# === 개선된 메인 실행 코드 ===\n",
    "def main():\n",
    "    folder = \"./camera_images2\"  # 폴더 경로 설정\n",
    "    \n",
    "    # 시각화 옵션 설정\n",
    "    viz_options = selective_visualization_control()\n",
    "    \n",
    "    # 폴더가 존재하지 않는 경우 현재 디렉토리에서 이미지 찾기\n",
    "    if not os.path.exists(folder):\n",
    "        print(f\"폴더 '{folder}'가 존재하지 않습니다. 현재 디렉토리에서 이미지를 찾습니다.\")\n",
    "        folder = \".\"\n",
    "    \n",
    "    # 이미지 로드\n",
    "    images, image_paths = load_images(folder)\n",
    "    \n",
    "    if len(images) < 2:\n",
    "        print(\"최소 2개의 이미지가 필요합니다.\")\n",
    "        return\n",
    "    \n",
    "    # 이미지 수가 많을 때 제한 옵션\n",
    "    if viz_options['show_first_n_images'] and len(images) > viz_options['show_first_n_images']:\n",
    "        print(f\"이미지가 {len(images)}개로 많아서 처음 {viz_options['show_first_n_images']}개만 처리합니다.\")\n",
    "        images = images[:viz_options['show_first_n_images']]\n",
    "        image_paths = image_paths[:viz_options['show_first_n_images']]\n",
    "    \n",
    "    # 특징점 검출 (ChArUco 또는 체커보드)\n",
    "    print(\"\\n특징점 검출 시작...\")\n",
    "    result = detect_charuco_with_fallback(images)\n",
    "    \n",
    "    if result[0] is None:\n",
    "        print(\"모든 검출 방법이 실패했습니다.\")\n",
    "        return\n",
    "    \n",
    "    corners_or_objpoints, ids_or_imgpoints, valid_images, detection_info, board, aruco_dict = result\n",
    "    \n",
    "    # 검출 타입 확인\n",
    "    detection_type = 'charuco' if board is not None else 'regular_checkerboard'\n",
    "    print(f\"\\n검출 타입: {detection_type}\")\n",
    "    \n",
    "    # 검출 결과 시각화 (개선된 버전)\n",
    "    if viz_options['show_detection_results']:\n",
    "        print(\"\\n검출 결과 시각화...\")\n",
    "        visualize_detection_results_batch(\n",
    "            valid_images, \n",
    "            detection_info, \n",
    "            max_images_per_plot=viz_options['max_images_per_plot'],\n",
    "            save_plots=viz_options['save_plots']\n",
    "        )\n",
    "    \n",
    "    # ==========================================\n",
    "    # 카메라 캘리브레이션 수행\n",
    "    # ==========================================\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"카메라 캘리브레이션 시작\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    ret, camera_matrix, dist_coeffs, rvecs, tvecs, reprojection_error = calibrate_camera_universal(\n",
    "        corners_or_objpoints, ids_or_imgpoints, valid_images, detection_info, board, detection_type\n",
    "    )\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"카메라 캘리브레이션에 실패했습니다.\")\n",
    "        return\n",
    "    \n",
    "    # 카메라 파라미터 분석\n",
    "    image_size = (valid_images[0].shape[1], valid_images[0].shape[0])\n",
    "    analysis = analyze_camera_parameters(camera_matrix, dist_coeffs, image_size)\n",
    "    \n",
    "    # ==========================================\n",
    "    # 각 이미지별 포즈 추정\n",
    "    # ==========================================\n",
    "    print(\"\\n각 이미지별 외부 파라미터 추정 중...\")\n",
    "    poses = estimate_pose_for_each_image(\n",
    "        corners_or_objpoints, ids_or_imgpoints, camera_matrix, dist_coeffs, \n",
    "        detection_info, board, detection_type\n",
    "    )\n",
    "    \n",
    "    # ==========================================\n",
    "    # 결과 출력 및 시각화\n",
    "    # ==========================================\n",
    "    \n",
    "    # 상세한 캘리브레이션 결과 출력\n",
    "    print_calibration_results(ret, camera_matrix, dist_coeffs, poses, analysis)\n",
    "    \n",
    "    # 재투영 오차 시각화 (개선된 버전)\n",
    "    if viz_options['show_reprojection_errors']:\n",
    "        print(\"\\n재투영 오차 시각화 생성 중...\")\n",
    "        visualize_reprojection_errors_improved(\n",
    "            valid_images, poses, corners_or_objpoints, ids_or_imgpoints,\n",
    "            camera_matrix, dist_coeffs, detection_info, board, detection_type,\n",
    "            max_images_per_plot=viz_options['max_images_per_plot']\n",
    "        )\n",
    "    \n",
    "    # ==========================================\n",
    "    # 특징점 매칭 및 호모그래피 계산 (추가 분석용)\n",
    "    # ==========================================\n",
    "    homographies = []\n",
    "    \n",
    "    if viz_options['show_feature_matching']:\n",
    "        print(\"\\n특징점 매칭 및 호모그래피 계산...\")\n",
    "        # 너무 많은 매칭 시각화를 방지하기 위해 최대 5개 쌍만 표시\n",
    "        max_pairs_to_show = min(viz_options['max_matching_pairs'], len(valid_images) - 1)\n",
    "        \n",
    "        for i in range(1, min(len(valid_images), max_pairs_to_show + 1)):\n",
    "            print(f\"\\n이미지 1과 이미지 {i+1} 간의 매칭...\")\n",
    "            \n",
    "            if detection_type == 'charuco':\n",
    "                data1 = (corners_or_objpoints[0], ids_or_imgpoints[0])\n",
    "                data2 = (corners_or_objpoints[i], ids_or_imgpoints[i])\n",
    "            else:\n",
    "                data1 = ids_or_imgpoints[0]  # imgpoints for regular checkerboard\n",
    "                data2 = ids_or_imgpoints[i]\n",
    "            \n",
    "            matched_points1, matched_points2, common_data = match_features_universal(\n",
    "                data1, data2, detection_type\n",
    "            )\n",
    "            \n",
    "            if matched_points1 is not None:\n",
    "                print(f\"매칭된 특징점 개수: {len(matched_points1)}\")\n",
    "                \n",
    "                # 매칭 결과 시각화 (개선된 버전)\n",
    "                visualize_matches_universal_improved(\n",
    "                    valid_images[0], valid_images[i],\n",
    "                    matched_points1, matched_points2,\n",
    "                    f\"Feature Point Matching: Image 1 vs Image {i+1}\",\n",
    "                    max_matches_display=viz_options['max_matches_display']\n",
    "                )\n",
    "                \n",
    "                # 호모그래피 계산\n",
    "                H, mask = compute_homography_ransac(matched_points1, matched_points2)\n",
    "                if H is not None:\n",
    "                    det_H = np.linalg.det(H)\n",
    "                    inlier_ratio = np.sum(mask) / len(mask)\n",
    "                    print(f\"호모그래피 행렬 {i}:\")\n",
    "                    print(H)\n",
    "                    print(f'det H: {det_H:.6f}')\n",
    "                    print(f\"인라이어 비율: {inlier_ratio:.2%}\")\n",
    "                    print(f\"인라이어 개수: {np.sum(mask)}/{len(mask)}\")\n",
    "                    homographies.append(H)\n",
    "            else:\n",
    "                print(\"충분한 매칭점을 찾을 수 없습니다.\")\n",
    "        \n",
    "        # 나머지 이미지들에 대해서는 호모그래피만 계산 (시각화 없이)\n",
    "        for i in range(max_pairs_to_show + 1, len(valid_images)):\n",
    "            if detection_type == 'charuco':\n",
    "                data1 = (corners_or_objpoints[0], ids_or_imgpoints[0])\n",
    "                data2 = (corners_or_objpoints[i], ids_or_imgpoints[i])\n",
    "            else:\n",
    "                data1 = ids_or_imgpoints[0]\n",
    "                data2 = ids_or_imgpoints[i]\n",
    "            \n",
    "            matched_points1, matched_points2, common_data = match_features_universal(\n",
    "                data1, data2, detection_type\n",
    "            )\n",
    "            \n",
    "            if matched_points1 is not None:\n",
    "                H, mask = compute_homography_ransac(matched_points1, matched_points2)\n",
    "                if H is not None:\n",
    "                    homographies.append(H)\n",
    "    \n",
    "    print(f\"\\n총 {len(homographies)}개의 호모그래피 행렬이 계산되었습니다.\")\n",
    "    \n",
    "    # ==========================================\n",
    "    # 최종 결과 정리\n",
    "    # ==========================================\n",
    "    calibration_results = {\n",
    "        'camera_matrix': camera_matrix,\n",
    "        'distortion_coefficients': dist_coeffs,\n",
    "        'reprojection_error': ret,\n",
    "        'poses': poses,\n",
    "        'analysis': analysis,\n",
    "        'homographies': homographies,\n",
    "        'detection_type': detection_type,\n",
    "        'valid_images': valid_images,\n",
    "        'detection_info': detection_info\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n🎉 캘리브레이션 완료!\")\n",
    "    print(f\"📊 사용된 이미지: {len(valid_images)}개\")\n",
    "    print(f\"📷 검출 방법: {detection_type}\")\n",
    "    print(f\"🎯 전체 재투영 오차: {ret:.4f} 픽셀\")\n",
    "    \n",
    "    # ==========================================\n",
    "    # 3D 카메라 뷰 시각화\n",
    "    # ==========================================\n",
    "    if viz_options['show_3d_camera_view']:\n",
    "        print(f\"\\n🎬 3D 카메라 뷰 생성 중...\")\n",
    "        plot_comprehensive_camera_view(calibration_results)\n",
    "    \n",
    "    return calibration_results\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    calibration_results = main()\n",
    "    \n",
    "    if calibration_results:\n",
    "        # 결과에 쉽게 접근할 수 있도록 변수 할당\n",
    "        K = calibration_results['camera_matrix']  # 카메라 내부 파라미터 행렬\n",
    "        dist_coeffs = calibration_results['distortion_coefficients']  # 왜곡 계수\n",
    "        poses = calibration_results['poses']  # 각 이미지의 [R,t]\n",
    "        homographies = calibration_results['homographies']  # 호모그래피 행렬들\n",
    "        \n",
    "        print(f\"\\n🔍 주요 결과 변수들:\")\n",
    "        print(f\"   • K (카메라 내부 파라미터): {K.shape} 행렬\")\n",
    "        print(f\"   • dist_coeffs (왜곡 계수): {dist_coeffs.shape} 벡터\") \n",
    "        print(f\"   • poses (외부 파라미터): {len(poses)}개 이미지의 [R,t]\")\n",
    "        print(f\"   • homographies: {len(homographies)}개 호모그래피 행렬\")\n",
    "        \n",
    "        print(f\"\\n💡 사용 예시:\")\n",
    "        print(f\"   • 카메라 행렬 접근: K = calibration_results['camera_matrix']\")\n",
    "        print(f\"   • 첫 번째 이미지 회전 행렬: R1 = poses[0][1]\")\n",
    "        print(f\"   • 첫 번째 이미지 변환 벡터: t1 = poses[0][2]\")\n",
    "        print(f\"   • 첫 번째 호모그래피: H1 = homographies[0]\")\n",
    "        \n",
    "        print(f\"\\n🎬 3D 시각화 정보:\")\n",
    "        print(f\"   • 빨간색 축: X축 (카메라 우측)\")\n",
    "        print(f\"   • 초록색 축: Y축 (카메라 아래)\")  \n",
    "        print(f\"   • 파란색 축: Z축 (카메라 전방)\")\n",
    "        print(f\"   • 회색 선: 카메라 시야각(프러스텀)\")\n",
    "        print(f\"   • 빨간 점: 체커보드 코너점들\")\n",
    "        print(f\"   • 검은 선: 체커보드 경계\")\n",
    "    else:\n",
    "        print(\"캘리브레이션이 실패했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cda6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def validate_calibration_comprehensive(calibration_results):\n",
    "    \"\"\"\n",
    "    캘리브레이션 품질을 종합적으로 검증하는 함수\n",
    "    \n",
    "    Args:\n",
    "        calibration_results: 이전 셀에서 생성된 캘리브레이션 결과\n",
    "    \n",
    "    Returns:\n",
    "        dict: 검증 결과 및 품질 평가\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"COMPREHENSIVE CALIBRATION QUALITY VALIDATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 결과 추출\n",
    "    camera_matrix = calibration_results['camera_matrix']\n",
    "    dist_coeffs = calibration_results['distortion_coefficients']\n",
    "    poses = calibration_results['poses']\n",
    "    homographies = calibration_results['homographies']\n",
    "    reprojection_error = calibration_results['reprojection_error']\n",
    "    valid_images = calibration_results['valid_images']\n",
    "    detection_info = calibration_results['detection_info']\n",
    "    \n",
    "    validation_results = {'overall_score': 0, 'max_score': 25}\n",
    "    \n",
    "    # 1. 재투영 오차 분석\n",
    "    print(\"\\n1. REPROJECTION ERROR ANALYSIS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    individual_errors = [pose[3] for pose in poses if pose[0] and len(pose) > 3 and pose[3] is not None]\n",
    "    \n",
    "    if individual_errors:\n",
    "        mean_error = np.mean(individual_errors)\n",
    "        std_error = np.std(individual_errors)\n",
    "        max_error = np.max(individual_errors)\n",
    "        min_error = np.min(individual_errors)\n",
    "        \n",
    "        print(f\"Overall RMS error: {reprojection_error:.4f} pixels\")\n",
    "        print(f\"Individual errors: {min_error:.4f} - {max_error:.4f} pixels\")\n",
    "        print(f\"Mean ± Std: {mean_error:.4f} ± {std_error:.4f} pixels\")\n",
    "        \n",
    "        # 재투영 오차 점수화 (5점 만점)\n",
    "        if reprojection_error < 0.5:\n",
    "            error_score = 5\n",
    "            error_grade = \"EXCELLENT\"\n",
    "        elif reprojection_error < 1.0:\n",
    "            error_score = 4  \n",
    "            error_grade = \"GOOD\"\n",
    "        elif reprojection_error < 2.0:\n",
    "            error_score = 3\n",
    "            error_grade = \"ACCEPTABLE\"\n",
    "        elif reprojection_error < 5.0:\n",
    "            error_score = 2\n",
    "            error_grade = \"POOR\"\n",
    "        else:\n",
    "            error_score = 1\n",
    "            error_grade = \"VERY POOR\"\n",
    "        \n",
    "        print(f\"Grade: {error_grade} ({error_score}/5 points)\")\n",
    "        validation_results['reprojection'] = {\n",
    "            'rms_error': reprojection_error,\n",
    "            'grade': error_grade,\n",
    "            'score': error_score\n",
    "        }\n",
    "        validation_results['overall_score'] += error_score\n",
    "    \n",
    "    # 2. 카메라 내부 파라미터 검증\n",
    "    print(\"\\n2. INTRINSIC PARAMETERS VALIDATION\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    fx, fy = camera_matrix[0, 0], camera_matrix[1, 1]\n",
    "    cx, cy = camera_matrix[0, 2], camera_matrix[1, 2]\n",
    "    \n",
    "    if valid_images:\n",
    "        img_height, img_width = valid_images[0].shape[:2]\n",
    "        \n",
    "        # 주점 오프셋 검사\n",
    "        center_offset_x = abs(cx - img_width/2) / img_width\n",
    "        center_offset_y = abs(cy - img_height/2) / img_height\n",
    "        max_center_offset = max(center_offset_x, center_offset_y)\n",
    "        \n",
    "        # 종횡비 검사\n",
    "        aspect_ratio = fx / fy\n",
    "        aspect_deviation = abs(aspect_ratio - 1.0)\n",
    "        \n",
    "        # 초점거리 합리성 검사\n",
    "        diagonal_pixels = np.sqrt(img_width**2 + img_height**2)\n",
    "        avg_focal_length = (fx + fy) / 2\n",
    "        focal_ratio = avg_focal_length / diagonal_pixels\n",
    "        \n",
    "        print(f\"Image size: {img_width} × {img_height}\")\n",
    "        print(f\"Focal lengths: fx={fx:.1f}, fy={fy:.1f}\")\n",
    "        print(f\"Principal point: ({cx:.1f}, {cy:.1f})\")\n",
    "        print(f\"Principal point offset: {max_center_offset:.2%}\")\n",
    "        print(f\"Aspect ratio (fx/fy): {aspect_ratio:.4f}\")\n",
    "        print(f\"Focal length ratio: {focal_ratio:.3f}\")\n",
    "        \n",
    "        # 내부 파라미터 점수화 (5점 만점)\n",
    "        intrinsic_score = 5\n",
    "        issues = []\n",
    "        \n",
    "        if max_center_offset > 0.1:  # 10% 이상 벗어남\n",
    "            intrinsic_score -= 1\n",
    "            issues.append(\"Principal point off-center\")\n",
    "        \n",
    "        if aspect_deviation > 0.05:  # 5% 이상 차이\n",
    "            intrinsic_score -= 1\n",
    "            issues.append(\"Significant aspect ratio deviation\")\n",
    "        \n",
    "        if focal_ratio < 0.5 or focal_ratio > 3.0:  # 비정상적 범위\n",
    "            intrinsic_score -= 2\n",
    "            issues.append(\"Unusual focal length\")\n",
    "        \n",
    "        if not issues:\n",
    "            print(\"✓ All intrinsic parameters look reasonable\")\n",
    "        else:\n",
    "            print(\"⚠ Issues detected:\")\n",
    "            for issue in issues:\n",
    "                print(f\"  - {issue}\")\n",
    "        \n",
    "        print(f\"Intrinsic score: {intrinsic_score}/5 points\")\n",
    "        validation_results['intrinsics'] = {\n",
    "            'score': intrinsic_score,\n",
    "            'issues': issues\n",
    "        }\n",
    "        validation_results['overall_score'] += intrinsic_score\n",
    "    \n",
    "    # 3. 호모그래피 검증\n",
    "    print(\"\\n3. HOMOGRAPHY VALIDATION\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    homography_score = 0\n",
    "    if homographies:\n",
    "        det_values = []\n",
    "        cond_values = []\n",
    "        \n",
    "        for i, H in enumerate(homographies):\n",
    "            det_H = np.linalg.det(H)\n",
    "            cond_H = np.linalg.cond(H)\n",
    "            \n",
    "            det_values.append(det_H)\n",
    "            cond_values.append(cond_H)\n",
    "            \n",
    "            print(f\"Homography {i+1}: det={det_H:.4f}, cond={cond_H:.1f}\")\n",
    "        \n",
    "        # 호모그래피 품질 평가 (5점 만점)\n",
    "        positive_dets = sum(1 for det in det_values if det > 0)\n",
    "        good_condition = sum(1 for cond in cond_values if cond < 100)\n",
    "        \n",
    "        det_ratio = positive_dets / len(det_values) if det_values else 0\n",
    "        cond_ratio = good_condition / len(cond_values) if cond_values else 0\n",
    "        \n",
    "        homography_score = int(2.5 * det_ratio + 2.5 * cond_ratio)\n",
    "        \n",
    "        print(f\"Positive determinants: {positive_dets}/{len(det_values)}\")\n",
    "        print(f\"Good condition numbers: {good_condition}/{len(cond_values)}\")\n",
    "        print(f\"Homography score: {homography_score}/5 points\")\n",
    "        \n",
    "        validation_results['homography'] = {\n",
    "            'score': homography_score,\n",
    "            'determinants': det_values,\n",
    "            'condition_numbers': cond_values\n",
    "        }\n",
    "    \n",
    "    validation_results['overall_score'] += homography_score\n",
    "    \n",
    "    # 4. 외부 파라미터 검증\n",
    "    print(\"\\n4. EXTRINSIC PARAMETERS VALIDATION\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    extrinsic_score = 0\n",
    "    successful_poses = [pose for pose in poses if pose[0]]\n",
    "    \n",
    "    if len(successful_poses) >= 2:\n",
    "        # 카메라 위치 추출\n",
    "        camera_positions = []\n",
    "        rotation_angles = []\n",
    "        \n",
    "        for success, R, t, error in successful_poses:\n",
    "            if success and R is not None and t is not None:\n",
    "                camera_center = (-R.T @ t).flatten()\n",
    "                camera_positions.append(camera_center)\n",
    "                \n",
    "                # 오일러 각도 계산\n",
    "                sy = np.sqrt(R[0,0] * R[0,0] + R[1,0] * R[1,0])\n",
    "                if sy > 1e-6:\n",
    "                    x = np.arctan2(R[2,1], R[2,2])\n",
    "                    y = np.arctan2(-R[2,0], sy)\n",
    "                    z = np.arctan2(R[1,0], R[0,0])\n",
    "                else:\n",
    "                    x = np.arctan2(-R[1,2], R[1,1])\n",
    "                    y = np.arctan2(-R[2,0], sy)\n",
    "                    z = 0\n",
    "                \n",
    "                rotation_angles.append([np.degrees(x), np.degrees(y), np.degrees(z)])\n",
    "        \n",
    "        camera_positions = np.array(camera_positions)\n",
    "        rotation_angles = np.array(rotation_angles)\n",
    "        \n",
    "        # 위치 일관성 검사\n",
    "        if len(camera_positions) > 1:\n",
    "            distances = []\n",
    "            for i in range(1, len(camera_positions)):\n",
    "                dist = np.linalg.norm(camera_positions[i] - camera_positions[i-1])\n",
    "                distances.append(dist)\n",
    "            \n",
    "            distance_std = np.std(distances) if distances else 0\n",
    "            mean_distance = np.mean(distances) if distances else 0\n",
    "            \n",
    "            print(f\"Camera positions:\")\n",
    "            for i, pos in enumerate(camera_positions):\n",
    "                print(f\"  Camera {i+1}: ({pos[0]:.3f}, {pos[1]:.3f}, {pos[2]:.3f})\")\n",
    "            \n",
    "            print(f\"Inter-camera distances: {mean_distance:.3f} ± {distance_std:.3f} m\")\n",
    "            \n",
    "            # 회전 일관성 검사\n",
    "            if len(rotation_angles) > 1:\n",
    "                rotation_std = np.std(rotation_angles, axis=0)\n",
    "                print(f\"Rotation variations: Roll={rotation_std[0]:.1f}°, Pitch={rotation_std[1]:.1f}°, Yaw={rotation_std[2]:.1f}°\")\n",
    "            \n",
    "            # 외부 파라미터 점수화 (5점 만점)\n",
    "            extrinsic_score = 5\n",
    "            \n",
    "            if distance_std / mean_distance > 0.5 if mean_distance > 0 else False:  # 거리 편차가 50% 이상\n",
    "                extrinsic_score -= 1\n",
    "                print(\"⚠ High variation in camera distances\")\n",
    "            \n",
    "            if np.any(rotation_std > 45):  # 회전 편차가 45도 이상\n",
    "                extrinsic_score -= 1\n",
    "                print(\"⚠ High variation in camera orientations\")\n",
    "            \n",
    "            print(f\"Extrinsic score: {extrinsic_score}/5 points\")\n",
    "    \n",
    "    validation_results['extrinsics'] = {'score': extrinsic_score}\n",
    "    validation_results['overall_score'] += extrinsic_score\n",
    "    \n",
    "    # 5. 기하학적 일관성 검증\n",
    "    print(\"\\n5. GEOMETRIC CONSISTENCY VALIDATION\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    geometric_score = 0\n",
    "    \n",
    "    if len(successful_poses) >= 2 and len(detection_info) >= 2:\n",
    "        # 에피폴라 기하학 검증 (단순화된 버전)\n",
    "        try:\n",
    "            # 첫 번째와 두 번째 이미지 간의 본질 행렬 계산\n",
    "            R1, t1 = successful_poses[0][1], successful_poses[0][2]\n",
    "            R2, t2 = successful_poses[1][1], successful_poses[1][2]\n",
    "            \n",
    "            # 상대 포즈 계산\n",
    "            R_rel = R2 @ R1.T\n",
    "            t_rel = t2 - R_rel @ t1\n",
    "            \n",
    "            # 본질 행렬 계산\n",
    "            t_skew = np.array([[0, -t_rel[2,0], t_rel[1,0]],\n",
    "                              [t_rel[2,0], 0, -t_rel[0,0]],\n",
    "                              [-t_rel[1,0], t_rel[0,0], 0]])\n",
    "            E = t_skew @ R_rel\n",
    "            \n",
    "            # 본질 행렬의 특이값 검사\n",
    "            U, S, Vt = np.linalg.svd(E)\n",
    "            singular_ratio = S[1] / S[0] if S[0] > 0 else 0\n",
    "            \n",
    "            print(f\"Essential matrix singular values: {S}\")\n",
    "            print(f\"Singular value ratio: {singular_ratio:.4f}\")\n",
    "            \n",
    "            # 기하학적 일관성 점수화 (5점 만점)\n",
    "            if 0.8 < singular_ratio < 1.2:  # 이상적으로는 두 개의 동일한 특이값\n",
    "                geometric_score = 5\n",
    "            elif 0.5 < singular_ratio < 1.5:\n",
    "                geometric_score = 3\n",
    "            else:\n",
    "                geometric_score = 1\n",
    "            \n",
    "            print(f\"Geometric consistency score: {geometric_score}/5 points\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Could not compute geometric consistency: {e}\")\n",
    "            geometric_score = 2  # 중간 점수\n",
    "    \n",
    "    validation_results['geometric'] = {'score': geometric_score}\n",
    "    validation_results['overall_score'] += geometric_score\n",
    "    \n",
    "    # 최종 평가\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"OVERALL QUALITY ASSESSMENT\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    total_score = validation_results['overall_score']\n",
    "    max_score = validation_results['max_score']\n",
    "    percentage = (total_score / max_score) * 100\n",
    "    \n",
    "    print(f\"Total Score: {total_score}/{max_score} ({percentage:.1f}%)\")\n",
    "    \n",
    "    if percentage >= 90:\n",
    "        overall_grade = \"EXCELLENT\"\n",
    "    elif percentage >= 80:\n",
    "        overall_grade = \"GOOD\"\n",
    "    elif percentage >= 70:\n",
    "        overall_grade = \"ACCEPTABLE\"\n",
    "    elif percentage >= 60:\n",
    "        overall_grade = \"POOR\"\n",
    "    else:\n",
    "        overall_grade = \"UNACCEPTABLE\"\n",
    "    \n",
    "    print(f\"Overall Grade: {overall_grade}\")\n",
    "    \n",
    "    # 개선 제안\n",
    "    print(f\"\\nRECOMMendations:\")\n",
    "    if validation_results.get('reprojection', {}).get('score', 0) < 3:\n",
    "        print(\"• Improve image quality and lighting conditions\")\n",
    "        print(\"• Use more images with better checkerboard detection\")\n",
    "        print(\"• Check for motion blur or focus issues\")\n",
    "    \n",
    "    if validation_results.get('intrinsics', {}).get('score', 0) < 4:\n",
    "        print(\"• Verify camera setup and lens distortion\")\n",
    "        print(\"• Use images covering the entire field of view\")\n",
    "    \n",
    "    if validation_results.get('homography', {}).get('score', 0) < 3:\n",
    "        print(\"• Ensure sufficient perspective change between images\")\n",
    "        print(\"• Avoid nearly parallel checkerboard orientations\")\n",
    "    \n",
    "    validation_results['overall_grade'] = overall_grade\n",
    "    validation_results['percentage'] = percentage\n",
    "    \n",
    "    return validation_results\n",
    "\n",
    "def plot_validation_summary(validation_results):\n",
    "    \"\"\"\n",
    "    검증 결과를 시각적으로 요약하는 함수\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # 점수 분포 차트\n",
    "    categories = ['Reprojection', 'Intrinsics', 'Homography', 'Extrinsics', 'Geometric']\n",
    "    scores = [\n",
    "        validation_results.get('reprojection', {}).get('score', 0),\n",
    "        validation_results.get('intrinsics', {}).get('score', 0),\n",
    "        validation_results.get('homography', {}).get('score', 0),\n",
    "        validation_results.get('extrinsics', {}).get('score', 0),\n",
    "        validation_results.get('geometric', {}).get('score', 0)\n",
    "    ]\n",
    "    \n",
    "    colors = ['red' if s < 3 else 'orange' if s < 4 else 'green' for s in scores]\n",
    "    \n",
    "    axes[0].bar(categories, scores, color=colors, alpha=0.7, edgecolor='black')\n",
    "    axes[0].set_ylim(0, 5)\n",
    "    axes[0].set_ylabel('Score')\n",
    "    axes[0].set_title('Calibration Quality Scores')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 전체 품질 게이지\n",
    "    percentage = validation_results.get('percentage', 0)\n",
    "    \n",
    "    theta = np.linspace(0, np.pi, 100)\n",
    "    r = np.ones_like(theta)\n",
    "    \n",
    "    axes[1] = plt.subplot(1, 2, 2, projection='polar')\n",
    "    axes[1].plot(theta, r, 'k-', linewidth=2)\n",
    "    axes[1].fill_between(theta, 0, r, alpha=0.1)\n",
    "    \n",
    "    # 점수에 따른 색상 섹션\n",
    "    sections = [(0, 60, 'red'), (60, 70, 'orange'), (70, 80, 'yellow'), (80, 90, 'lightgreen'), (90, 100, 'green')]\n",
    "    \n",
    "    for start, end, color in sections:\n",
    "        section_theta = np.linspace(start/100 * np.pi, end/100 * np.pi, 20)\n",
    "        section_r = np.ones_like(section_theta)\n",
    "        axes[1].fill_between(section_theta, 0, section_r, color=color, alpha=0.3)\n",
    "    \n",
    "    # 현재 점수 표시\n",
    "    current_theta = percentage/100 * np.pi\n",
    "    axes[1].plot([current_theta, current_theta], [0, 1], 'k-', linewidth=3)\n",
    "    axes[1].scatter([current_theta], [0.8], s=200, c='black', marker='o')\n",
    "    \n",
    "    axes[1].set_ylim(0, 1)\n",
    "    axes[1].set_theta_zero_location('W')\n",
    "    axes[1].set_theta_direction(1)\n",
    "    axes[1].set_thetagrids(np.arange(0, 181, 30), ['0%', '17%', '33%', '50%', '67%', '83%', '100%'])\n",
    "    axes[1].set_title(f'Overall Quality: {percentage:.1f}%\\n{validation_results.get(\"overall_grade\", \"Unknown\")}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 실행 코드\n",
    "if 'calibration_results' in globals():\n",
    "    print(\"Found calibration results from previous cell. Starting validation...\")\n",
    "    validation_results = validate_calibration_comprehensive(calibration_results)\n",
    "    plot_validation_summary(validation_results)\n",
    "    \n",
    "    # 결과 저장\n",
    "    validation_summary = {\n",
    "        'overall_score': validation_results['overall_score'],\n",
    "        'overall_grade': validation_results['overall_grade'],\n",
    "        'percentage': validation_results['percentage'],\n",
    "        'reprojection_error': validation_results.get('reprojection', {}).get('rms_error', 0)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n📊 VALIDATION SUMMARY:\")\n",
    "    print(f\"   Score: {validation_summary['overall_score']}/25\")\n",
    "    print(f\"   Grade: {validation_summary['overall_grade']}\")\n",
    "    print(f\"   Percentage: {validation_summary['percentage']:.1f}%\")\n",
    "    print(f\"   RMS Error: {validation_summary['reprojection_error']:.4f} pixels\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Error: 'calibration_results' not found.\")\n",
    "    print(\"Please run the calibration code in the previous cell first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3D_CV_bw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
